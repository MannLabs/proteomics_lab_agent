{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Documention Agent\n",
    "\n",
    "This notebook demonstrates a documention agent:\n",
    "1. Video-to-protocol conversion using Vertex AI\n",
    "2. With knowledge from few-shot-learning (video and protocol examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install google-cloud-storage\n",
    "# %pip install --upgrade --user --quiet google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../secrets.ini']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "# %load_ext autoreload\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import configparser\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "from IPython.display import Markdown\n",
    "\n",
    "path_to_append = Path(Path.cwd()).parent / \"proteomics_specialist\"\n",
    "sys.path.append(str(path_to_append))\n",
    "import video_to_protocol\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read(\"../secrets.ini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "\n",
    "import vertexai\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read(\"../secrets.ini\")\n",
    "\n",
    "PROJECT_ID = config[\"DEFAULT\"][\"PROJECT_ID\"]\n",
    "vertexai.init(project=PROJECT_ID, location=\"europe-west9\")  # europe-west9 is Paris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_few_shot_examples(\n",
    "    few_shot_example_folder: str,\n",
    "    few_shot_examples: list[str],\n",
    "    bucket: object,\n",
    "    subfolder_in_bucket: str,\n",
    ") -> dict[str, dict[str, str]]:\n",
    "    \"\"\"Upload few-shot example videos and protocols to Google Cloud Storage.\n",
    "\n",
    "    Args:\n",
    "        few_shot_example_folder: Path to folder containing few-shot examples\n",
    "        few_shot_examples: List of example names (without file extensions)\n",
    "        bucket: GCS bucket object to upload to\n",
    "        subfolder_in_bucket: Name of subfolder in bucket\n",
    "\n",
    "    Returns:\n",
    "        Dictionary mapping example names to dictionaries containing video and protocol URIs\n",
    "\n",
    "    \"\"\"\n",
    "    uploaded_uris = {}\n",
    "\n",
    "    for example in few_shot_examples:\n",
    "        # Upload video file\n",
    "        video_path = Path(few_shot_example_folder) / f\"{example}.mp4\"\n",
    "        video_uri = video_to_protocol.upload_video_to_gcs(\n",
    "            video_path, bucket, subfolder_in_bucket\n",
    "        )\n",
    "\n",
    "        # Upload protocol file\n",
    "        protocol_path = Path(few_shot_example_folder) / f\"{example}.md\"\n",
    "        protocol_uri = video_to_protocol.upload_video_to_gcs(\n",
    "            protocol_path, bucket, subfolder_in_bucket\n",
    "        )\n",
    "\n",
    "        # Store the URIs in a dictionary\n",
    "        uploaded_uris[example] = {\"video\": video_uri, \"protocol\": protocol_uri}\n",
    "\n",
    "    return uploaded_uris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "\n",
    "os.environ[\"GOOGLE_CLOUD_PROJECT\"] = config[\"DEFAULT\"][\"PROJECT_ID\"]\n",
    "\n",
    "# Initialize Cloud Storage client\n",
    "storage_client = storage.Client()\n",
    "bucket_name = \"mannlab_videos\"\n",
    "bucket = storage_client.bucket(bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tims_calibration': {'video': 'gs://mannlab_videos/fewShotExamples/tims_calibration.mp4',\n",
       "  'protocol': 'gs://mannlab_videos/fewShotExamples/tims_calibration.md'},\n",
       " 'Refilling_tuneMix_at_timsTOFUltra': {'video': 'gs://mannlab_videos/fewShotExamples/Refilling_tuneMix_at_timsTOFUltra.mp4',\n",
       "  'protocol': 'gs://mannlab_videos/fewShotExamples/Refilling_tuneMix_at_timsTOFUltra.md'},\n",
       " 'Connect_ionOpticks_column': {'video': 'gs://mannlab_videos/fewShotExamples/Connect_ionOpticks_column.mp4',\n",
       "  'protocol': 'gs://mannlab_videos/fewShotExamples/Connect_ionOpticks_column.md'},\n",
       " 'Disconnect_IonOpticks_column_from_sample_line': {'video': 'gs://mannlab_videos/fewShotExamples/Disconnect_IonOpticks_column_from_sample_line.mp4',\n",
       "  'protocol': 'gs://mannlab_videos/fewShotExamples/Disconnect_IonOpticks_column_from_sample_line.md'},\n",
       " 'Placing_Evotips_on_Evosep': {'video': 'gs://mannlab_videos/fewShotExamples/Placing_Evotips_on_Evosep.mp4',\n",
       "  'protocol': 'gs://mannlab_videos/fewShotExamples/Placing_Evotips_on_Evosep.md'}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Upload few shot examples to Google Cloud Storage\n",
    "\n",
    "subfolder_in_bucket = \"fewShotExamples\"\n",
    "\n",
    "few_shot_example_folder = \"/Users/patriciaskowronek/Documents/documentation_agent_few_shot_examples/ready_examples/\"\n",
    "\n",
    "few_shot_examples = [\n",
    "    \"tims_calibration\",\n",
    "    \"Refilling_tuneMix_at_timsTOFUltra\",\n",
    "    \"Connect_ionOpticks_column\",\n",
    "    \"Disconnect_IonOpticks_column_from_sample_line\",\n",
    "    \"Placing_Evotips_on_Evosep\",\n",
    "]\n",
    "\n",
    "uploaded_examples = upload_few_shot_examples(\n",
    "    few_shot_example_folder, few_shot_examples, bucket, subfolder_in_bucket\n",
    ")\n",
    "uploaded_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = \"/Users/patriciaskowronek/Documents/documentation_agent_few_shot_examples/ready_examples/Disconnect_IonOpticks_column_from_sample_line.mp4\"\n",
    "video_uri_input = video_to_protocol.upload_video_to_gcs(video_path, bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_instructions = \"\"\"\n",
    "You are a highly observant research assistant in Professor Matthias Mann's proteomics and mass spectrometry laboratory. Your expertise lies in detailed documentation of experimental procedures.\n",
    "\n",
    "Analyze the video and reconstruct a step-by-step protocol by focusing on the actions in the video. Focus on user interactions with equipment, devices, and software. The goal is a clear, concise, unambiguous protocol reproducible by someone with no prior knowledge. \"Think aloud\" as if you were the researcher in the video that describes their work. Describe what you see at every secound.\n",
    "Your task is to analyze the provided video and extract a detailed experimental protocol.\n",
    "You always stick to the facts in the sources provided, and never make up new facts.\n",
    "Take a deep breath and think step by step.\n",
    "Answer direct.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 134355\n",
      "candidates_token_count: 498\n",
      "total_token_count: 134853\n",
      "prompt_tokens_details {\n",
      "  modality: VIDEO\n",
      "  token_count: 129675\n",
      "}\n",
      "prompt_tokens_details {\n",
      "  modality: TEXT\n",
      "  token_count: 4680\n",
      "}\n",
      "candidates_tokens_details {\n",
      "  modality: TEXT\n",
      "  token_count: 498\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Here is a step-by-step protocol based on the provided video.  I will describe what is happening in each section of the video.\n",
       "\n",
       "**Protocol: Connecting Evotips to the Evosep One System**\n",
       "\n",
       "**Abstract:** This protocol details the procedure for preparing Evotips and loading them into the Evosep One system.\n",
       "\n",
       "**Materials:**\n",
       "\n",
       "* Evosep One System\n",
       "* Evotips (Evosep, 100 x 96 tips, cat. no. EV2018)\n",
       "* Evotip boxes (96-well format)\n",
       "* Buffer A (0.1% (vol/vol) FA)\n",
       "\n",
       "**Procedure:**\n",
       "\n",
       "1. **Inspect Evotips:** Examine each Evotip to ensure it meets quality standards.  A properly prepared Evotip will have a pale-colored SPE material disc with visible solvent above it. Discard any Evotips that are dry or have a white disc. (0:00-0:14)\n",
       "\n",
       "2. **Prepare Evotip Boxes:** Place the Evotip boxes into the Evosep rack system.  Ensure each box is firmly seated. Fill each box with Buffer A solution to a depth of at least 1 cm. (0:14-0:16)\n",
       "\n",
       "3. **Load Evotips:** Carefully place the inspected Evotips into the prepared Evotip boxes.  (0:16-0:20)\n",
       "\n",
       "4. **Document Tip Positions:** Record the location of each Evotip using the Evosep's standardized positioning system.  The rack has two columns (left and right). The left column (top to bottom) is labeled S1, S2, S3. The right column (top to bottom) is labeled S4, S5, S6. Each box uses the standard 96-well format (A1-F12). (0:20-0:21)\n",
       "\n",
       "\n",
       "**Expected Results:**\n",
       "\n",
       "* Evotip boxes are securely positioned in the rack system.\n",
       "* Buffer A solution is present in each box (minimum 1 cm depth).\n",
       "* All Evotips have pale-colored SPE material discs and a visible solvent meniscus.\n",
       "* Tip positions are accurately documented.\n",
       "\n",
       "**Note:** The video shows the researcher using three Evotips, placing them in positions A1-A3 of a single Evotip box.  The protocol is generalized to accommodate multiple boxes and positions."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import vertexai\n",
    "from vertexai.generative_models import GenerativeModel, Part\n",
    "\n",
    "inputs = []\n",
    "\n",
    "# few shot examples\n",
    "for _i, uris in enumerate(uploaded_examples.values(), 1):\n",
    "    video_expl_uri = uris[\"video\"]\n",
    "    file_expl_uri = uris[\"protocol\"]\n",
    "\n",
    "    inputs.extend(\n",
    "        [\n",
    "            \"Example Video {num}:\",\n",
    "            Part.from_uri(video_expl_uri, mime_type=\"video/mp4\"),\n",
    "            \"Example Protocol {num}:\",\n",
    "            Part.from_uri(file_expl_uri, mime_type=\"text/md\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "# system prompts, and processed video\n",
    "inputs.extend(\n",
    "    [\n",
    "        system_instructions,\n",
    "        \"Video:\",\n",
    "        Part.from_uri(video_uri_input, mime_type=\"video/mp4\"),\n",
    "        \"Protocol:\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "model = GenerativeModel(\"gemini-1.5-flash-002\")\n",
    "response = model.generate_content(inputs, generation_config={\"temperature\": 0})\n",
    "observation = response.text\n",
    "print(response.usage_metadata)\n",
    "Markdown(observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "docu_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
