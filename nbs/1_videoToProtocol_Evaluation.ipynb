{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Protocol evaluation pipeline\n",
    "\n",
    "Comparing AI generated protocols with ground truth (gt) protocols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "# %load_ext autoreload\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import configparser\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Type checking imports\n",
    "from typing import TYPE_CHECKING, Any, NoReturn\n",
    "from collections.abc import Callable\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import Markdown\n",
    "from vertexai.generative_models import Part\n",
    "\n",
    "path_to_append = Path(Path.cwd()).parent / \"proteomics_specialist\"\n",
    "sys.path.append(str(path_to_append))\n",
    "import evaluation\n",
    "import video_to_protocol\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read(\"../secrets.ini\")\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO, format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "\n",
    "import vertexai\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read(\"../secrets.ini\")\n",
    "\n",
    "PROJECT_ID = config[\"DEFAULT\"][\"PROJECT_ID\"]\n",
    "vertexai.init(project=PROJECT_ID, location=\"us-central1\")  # europe-west9 is Paris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "\n",
    "os.environ[\"GOOGLE_CLOUD_PROJECT\"] = config[\"DEFAULT\"][\"PROJECT_ID\"]\n",
    "\n",
    "storage_client = storage.Client()\n",
    "bucket_name = \"mannlab_videos\"\n",
    "bucket = storage_client.bucket(bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_protocols_evaluation(\n",
    "    protocol_gt: list[str],\n",
    "    protocol_ai: list[str],\n",
    "    model_name: str = \"gemini-2.5-pro-preview-03-25\",\n",
    "    temperature: float = 0.9,\n",
    ") -> tuple[str, Any]:\n",
    "    \"\"\"Generate an evaluation of AI-generated protocols against ground truth protocols.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    protocol_gt : list[str]\n",
    "        The ground truth protocols (benchmark) represented as a list of strings\n",
    "    protocol_ai : list[str]\n",
    "        The AI-generated protocols to evaluate represented as a list of strings\n",
    "    model_name : str, optional\n",
    "        The model to use for evaluation, by default \"gemini-2.5-pro-preview-03-25\"\n",
    "    temperature : float, optional\n",
    "        Temperature setting for content generation, by default 0.9\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple[str, Any]\n",
    "        A tuple containing (evaluation_text, usage_metadata)\n",
    "\n",
    "    \"\"\"\n",
    "    inputs = [\n",
    "        \"\"\"\n",
    "        # Instruction\n",
    "\n",
    "        You are an expert evaluator. Your task is to evaluate the quality of a protocol generated by an AI model by comparing it to a ground truth protocol. You will conduct a systematic, section-by-section analysis to determine how well the AI-generated protocol aligns with the ground truth protocol. You should first read the protocols carefully and then evaluate the quality of the AI-generated protocol based on the evaluation criteria below.\\n\n",
    "        # Evaluation\n",
    "\n",
    "        ## Evaluation Criteria\n",
    "        * Completeness: What is present in both protocols. What is present in the ground truth but missing from the AI-generated protocol. What is present in the AI-generated protocol but not in the ground truth\n",
    "        * Technical Accuracy: The AI-generated protocol demonstrates scientific understanding by properly distinguishing between different techniques and equipment and using appropriate scientific terminology.\n",
    "        * Logical Flow: The workflow maintains the chronological sequence of the procedure.\n",
    "        * Safety: The appropriate identification and emphasis of critical cautions, warnings, and safety measures.\n",
    "        * Formatting: The AI-generated protocol matches the formatting of the ground truth protocol.\n",
    "\n",
    "        ## Rating Rubric\n",
    "\n",
    "        For each criterion, rate the AI-generated protocol on a scale of 1-5:\n",
    "\n",
    "        5: (Very good). The AI-generated protocol demonstrates exceptional quality in this aspect, with no significant flaws or omissions. Fully meets or exceeds the ground truth protocol.\n",
    "        4: (Good). The AI-generated protocol demonstrates strong quality in this aspect, with only minor shortcomings that don't significantly impact effectiveness. Closely aligns with the ground truth protocol.\n",
    "        3: (Ok). The AI-generated protocol contains most essential elements but has noticeable differences from the ground truth protocol that might slightly impact its effectiveness.\n",
    "        2: (Bad). The AI-generated protocol has significant deficiencies in multiple criteria from the ground truth, missing or wrongly displaying important information that would likely impact its effectiveness.\n",
    "        1: (Very bad). The AI-generated protocol fails to meet minimum standards in this aspect, with fundamental flaws or critical omissions that render the content potentially unusable or unsafe.\n",
    "\n",
    "        ## Evaluation Steps\n",
    "\n",
    "        * Step 1: Read the 'Ground truth protocol' thoroughly and write it down again word-by-word (Verbatim).\n",
    "\n",
    "        * Step 2: Read the 'AI-generated protocol' thoroughly and write it down again word-by-word (Verbatim).\n",
    "\n",
    "        * Step 3: Compare each section of the AI-generated protocol with its counterpart in the ground truth protocol:\n",
    "\n",
    "        1. Title\n",
    "        2. Abstract\n",
    "        3. Materials\n",
    "        5. Each step from Expected Results\n",
    "        6. Figures\n",
    "        7. References\n",
    "\n",
    "        For each section, note how they fullfill the evaluation criteria (Completeness, Technical Accuracy, Logical Flow, Safety, Formatting) using the 1-5 scale based on the Rating Rubric. Treat the ground truth as the gold standard and more trustworthy protocol.\n",
    "\n",
    "        * Step 4: Comparative Analysis Table\n",
    "        Create a table summarizing your findings:\n",
    "\n",
    "        | Section | Ground Truth Protocol | AI-Generated Protocol | Completeness Rating (1-5) | Completeness Explanation | Technical Accuracy Rating (1-5) | Technical Accuracy Explanation | Logical Flow Rating (1-5) | Logical Flow Explanation | Safety Rating (1-5) | Safety Explanation | Formatting Rating (1-5) | Formatting Explanation | Notes |\n",
    "        |-|-|-|-|-|-|-|-|-|-|-|-|-|-|\n",
    "        | Title | [Text from ground truth] | [Text from AI protocol] | [1-5] | [Explanation] | [1-5] | [Explanation] | [1-5] | [Explanation] | [1-5] | [Explanation] | [1-5] | [Explanation] | [Additional observations or comments] |Misaligned/Not applicable] | [Explanation] |\n",
    "        | Abstract | [Text from ground truth] | [Text from AI protocol] | [1-5] | [Explanation] | [1-5] | [Explanation] | [1-5] | [Explanation] | [1-5] | [Explanation] | [1-5] | [Explanation] | [Additional observations or comments] |\n",
    "        | Materials - e.g. Equipment | [Text from ground truth] | [Text from AI protocol] | [1-5] | [Explanation] | [1-5] | [Explanation] | [1-5] | [Explanation] | [1-5] | [Explanation] | [1-5] | [Explanation] | [Additional observations or comments] |\n",
    "        | Materials - e.g. Reagents | [Text from ground truth] | [Text from AI protocol] | [1-5] | [Explanation] | [1-5] | [Explanation] | [1-5] | [Explanation] | [1-5] | [Explanation] | [1-5] | [Explanation] | [Additional observations or comments] |\n",
    "        | Procedure - Step 1 | [Text from ground truth] | [Text from AI protocol] | [1-5] | [Explanation] | [1-5] | [Explanation] | [1-5] | [Explanation] | [1-5] | [Explanation] | [1-5] | [Explanation] | [Additional observations or comments] |\n",
    "        | Procedure - Step 2 | [Text from ground truth] | [Text from AI protocol] | [1-5] | [Explanation] | [1-5] | [Explanation] | [1-5] | [Explanation] | [1-5] | [Explanation] | [1-5] | [Explanation] | [Additional observations or comments] |\n",
    "        | Procedure - Step 3 | [Text from ground truth] | [Text from AI protocol] | [1-5] | [Explanation] | [1-5] | [Explanation] | [1-5] | [Explanation] | [1-5] | [Explanation] | [1-5] | [Explanation] | [Additional observations or comments] |\n",
    "        | Procedure - Step 4 | [Text from ground truth] | [Text from AI protocol] | [1-5] | [Explanation] | [1-5] | [Explanation] | [1-5] | [Explanation] | [1-5] | [Explanation] | [1-5] | [Explanation] | [Additional observations or comments] |\n",
    "        | Procedure - Step 5 | [Text from ground truth] | [Text from AI protocol] | [1-5] | [Explanation] | [1-5] | [Explanation] | [1-5] | [Explanation] | [1-5] | [Explanation] | [1-5] | [Explanation] | [Additional observations or comments] |\n",
    "        | [Continue for all steps] | | | | | | | | | | | | | |\n",
    "        | Expected Results | [Text from ground truth] | [Text from AI protocol] | [1-5] | [Explanation] | [1-5] | [Explanation] | [1-5] | [Explanation] | [1-5] | [Explanation] | [1-5] | [Explanation] | [Additional observations or comments] |\n",
    "        | Figures | [Text from ground truth] | [Text from AI protocol] | [1-5] | [Explanation] | [1-5] | [Explanation] | [1-5] | [Explanation] | [1-5] | [Explanation] | [1-5] | [Explanation] | [Additional observations or comments] |\n",
    "        | References | [Text from ground truth] | [Text from AI protocol] | [1-5] | [Explanation] | [1-5] | [Explanation] | [1-5] | [Explanation] | [1-5] | [Explanation] | [1-5] | [Explanation] | [Additional observations or comments] |\n",
    "\n",
    "        * Step 5: Overall Summary:\n",
    "        Overall compare all sections in total and individually for Completeness, Technical Accuracy, Logical Flow, Safety, Formatting\n",
    "\n",
    "        * Step 6: Overall Rating\n",
    "        Provide an overall rating (1-5) based on step 5 and the Rating Rubric.\n",
    "\n",
    "        # Protocols for Evaluation\n",
    "\n",
    "        ## Ground Truth Protocol:\n",
    "        \"\"\"\n",
    "    ]\n",
    "\n",
    "    inputs.extend(protocol_gt)\n",
    "\n",
    "    inputs.extend([\"## AI-Generated Protocol:\"])\n",
    "    inputs.extend([protocol_ai])\n",
    "    inputs.extend([\"# Evaluation result:\"])\n",
    "\n",
    "    evaluation, usage_metadata = video_to_protocol.generate_content_from_model(\n",
    "        inputs,\n",
    "        model_name=model_name,\n",
    "        temperature=temperature,\n",
    "    )\n",
    "\n",
    "    return evaluation, usage_metadata\n",
    "\n",
    "\n",
    "def calculate_protocol_ratings(\n",
    "    df_eval: pd.DataFrame,\n",
    "    completeness_col: str = \"Completeness Rating (1-5)\",\n",
    "    accuracy_col: str = \"Technical Accuracy Rating (1-5)\",\n",
    "    logic_col: str = \"Logical Flow Rating (1-5)\",\n",
    "    safety_col: str = \"Safety Rating (1-5)\",\n",
    "    formatting_col: str = \"Formatting Rating (1-5)\",\n",
    ") -> dict:\n",
    "    \"\"\"Calculate average ratings across evaluation criteria from a dataframe of protocol evaluations.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df_eval : pd.DataFrame\n",
    "        DataFrame containing evaluation ratings for protocols\n",
    "    completeness_col : str, optional\n",
    "        Column name for completeness ratings, by default \"Completeness Rating (1-5)\"\n",
    "    accuracy_col : str, optional\n",
    "        Column name for technical accuracy ratings, by default \"Technical Accuracy Rating (1-5)\"\n",
    "    logic_col : str, optional\n",
    "        Column name for logical flow ratings, by default \"Logical Flow Rating (1-5)\"\n",
    "    safety_col : str, optional\n",
    "        Column name for safety ratings, by default \"Safety Rating (1-5)\"\n",
    "    formatting_col : str, optional\n",
    "        Column name for formatting ratings, by default \"Formatting Rating (1-5)\"\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Dictionary containing average ratings for each criterion and an overall rating\n",
    "\n",
    "    \"\"\"\n",
    "    mean_completeness = pd.to_numeric(df_eval[completeness_col], errors=\"coerce\").mean()\n",
    "    mean_accuracy = pd.to_numeric(df_eval[accuracy_col], errors=\"coerce\").mean()\n",
    "    mean_logic = pd.to_numeric(df_eval[logic_col], errors=\"coerce\").mean()\n",
    "    mean_safety = pd.to_numeric(df_eval[safety_col], errors=\"coerce\").mean()\n",
    "    mean_formatting = pd.to_numeric(df_eval[formatting_col], errors=\"coerce\").mean()\n",
    "\n",
    "    return {\n",
    "        \"Completeness\": mean_completeness,\n",
    "        \"Technical Accuracy\": mean_accuracy,\n",
    "        \"Logical Flow\": mean_logic,\n",
    "        \"Safety\": mean_safety,\n",
    "        \"Formatting\": mean_formatting,\n",
    "        \"Overall\": np.mean(\n",
    "            [mean_completeness, mean_accuracy, mean_logic, mean_safety, mean_formatting]\n",
    "        ),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protocol_ai = \"\"\"\n",
    "# Connecting an IonOpticks Column to a timsTOF SCP Instrument\n",
    "\n",
    "## Abstract\n",
    "This protocol describes the procedure for connecting an IonOpticks column to a timsTOF SCP instrument. It includes steps for ensuring proper connection of the sample line, grounding the column, and setting the column oven temperature. The protocol also covers checking the instrument status and idle flow using the timsControl and HyStar software.\n",
    "\n",
    "## Materials\n",
    "### Equipment\n",
    "* timsTOF SCP instrument\n",
    "* IonOpticks column\n",
    "* Sample line with nano connector\n",
    "* Nano connector adapter\n",
    "* Pliers\n",
    "* Column oven\n",
    "* Computer with timsControl software\n",
    "* Computer with HyStar software\n",
    "\n",
    "### Reagents\n",
    "* Solvent for the IonOpticks column (as recommended by the manufacturer)\n",
    "\n",
    "## Procedure\n",
    "\n",
    "**Estimated timing: 5 minutes**\n",
    "\n",
    "1. Check the software. Ensure that the timsTOF SCP instrument is in standby mode in the timsControl software. If the instrument is in operate mode, switch it to standby mode.\n",
    "2. Connect the column to the sample line. a. Insert the IonOpticks column into the Ultrasource. b. Connect the nano connector adapter to the sample line. c. Connect the sample line to the column using the adapter. d. Check for leaks by visually inspecting the connection for any liquid droplets. If there are leaks, tighten the connection or replace the column or emitter.\n",
    "3. Secure the connection. Use pliers to tighten the sample line connector to the column. Ensure that the connection is finger tight but not over tightened.\n",
    "4. Remove the adapter. Carefully remove the nano connector adapter from the sample line.\n",
    "5. Position the column oven. a. Loosen the screw on the column oven to adjust its position. b. Move the oven as close as possible to the source. c. Tighten the screw to secure the oven in place.\n",
    "6. Ground the column. a. Locate the grounding screw on the column oven. b. Use the screw to ground the column to the oven. c. If the column is longer, use the additional grounding screw on the oven to ensure proper grounding.\n",
    "7. Close the column oven. Ensure that the lid is securely closed.\n",
    "8. Set the column oven temperature. a. Check the temperature indicator on the column oven. b. Adjust the temperature to 50Â°C for IonOpticks columns. The temperature is indicated by three illuminated LEDs on the column toaster. c. Wait for the temperature to stabilize. The lights will stop blinking when the temperature is stable.\n",
    "9. Switch the instrument to operate mode. In the timsControl software, click the on/off button to switch the instrument to operate mode.\n",
    "10. Check the idle flow. In the HyStar software, check that the idle flow is on. If it is not, right-click on the Evosep logo, select 'Preparation', then select 'Idle flow' and 'Run'.\n",
    "11. Confirm signal. Verify that there is signal in the timsControl and HyStar software.\n",
    "\n",
    "## Expected Results\n",
    "After completing these steps, the IonOpticks column should be properly connected to the timsTOF SCP instrument. The instrument should be in operate mode, the idle flow should be on, and there should be signal in both the timsControl and HyStar software.\n",
    "\n",
    "## Figures\n",
    "* Figure 1: Overview of the timsTOF SCP instrument and its components.\n",
    "* Figure 2: Close-up view of the column oven and the grounding screw.\n",
    "* Figure 3: Screenshot of the timsControl software showing the instrument status and parameters.\n",
    "* Figure 4: Screenshot of the HyStar software showing the idle flow status.\n",
    "\n",
    "## References\n",
    "* IonOpticks column manufacturer's instructions\n",
    "* timsTOF SCP instrument user manual\n",
    "* timsControl software user manual\n",
    "* HyStar software user manual\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/patriciaskowronek/Documents/proteomics_specialist/data/ConnectingColumnSampleLine_protocolCorrect.md\"\n",
    "\n",
    "protocol_gt_uri = video_to_protocol.upload_file_to_gcs(path, bucket)\n",
    "protocol_gt = [Part.from_uri(protocol_gt_uri, mime_type=\"text/md\")]\n",
    "\n",
    "evaluation_response, usage_metadata = generate_protocols_evaluation(\n",
    "    protocol_gt,\n",
    "    protocol_ai,\n",
    "    model_name=\"gemini-2.5-pro-preview-03-25\",\n",
    "    temperature=0.9,\n",
    ")\n",
    "display(Markdown(evaluation_response))\n",
    "\n",
    "df_eval = eval.extract_table_to_dataframe(\n",
    "    evaluation,\n",
    "    \"Comparative Analysis\",\n",
    "    model_name=\"gemini-2.5-pro-preview-03-25\",\n",
    "    temperature=0.9,\n",
    ")\n",
    "\n",
    "ratings_dict = calculate_protocol_ratings(df_eval)\n",
    "display(ratings_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TYPE_CHECKING:\n",
    "    from google.cloud.storage import Bucket\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "MIME_TYPES = {\n",
    "    \".pdf\": \"application/pdf\",\n",
    "    \".jpg\": \"image/jpeg\",\n",
    "    \".jpeg\": \"image/jpeg\",\n",
    "    \".png\": \"image/png\",\n",
    "}\n",
    "\n",
    "\n",
    "def prepare_all_inputs(\n",
    "    protocol_video_path: str,\n",
    "    protocol_path: str,\n",
    "    bucket: str,\n",
    "    prefix: str = \"generate_protocol_video\",\n",
    ") -> dict:\n",
    "    \"\"\"Prepare all inputs for the generative model.\n",
    "\n",
    "    This function uploads files and formats them as inputs for a generative model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    protocol_video_path : str\n",
    "        Path to the file that shows the correct execution (ground truth) of the protocol.\n",
    "    protocol_path : str\n",
    "        Path to the protocol markdown file.\n",
    "    bucket : str\n",
    "        GCS bucket name for uploading the files.\n",
    "    prefix : str, default=\"compare_protocol_video\"\n",
    "        Prefix for the files in GCS bucket.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        A dictionary containing the four formatted inputs:\n",
    "        'protocol_video_input', 'protocol_input'\n",
    "\n",
    "    \"\"\"\n",
    "    video_uri = video_to_protocol.upload_file_to_gcs(\n",
    "        protocol_video_path, bucket, prefix\n",
    "    )\n",
    "    file_extension = Path(video_uri).suffix.lower()[1:]\n",
    "    protocol_video_input = [\n",
    "        Part.from_uri(video_uri, mime_type=f\"video/{file_extension}\")\n",
    "    ]\n",
    "\n",
    "    uri = video_to_protocol.upload_file_to_gcs(protocol_path, bucket, prefix)\n",
    "    protocol_ground_truth = [Part.from_uri(uri, mime_type=\"text/md\")]\n",
    "\n",
    "    return {\n",
    "        \"protocol_video_input\": protocol_video_input,\n",
    "        \"protocol_input\": protocol_ground_truth,\n",
    "    }\n",
    "\n",
    "\n",
    "def process_benchmark_dataset(\n",
    "    csv_path: str | Path,\n",
    "    protocol_videos_base: str | Path,\n",
    "    markdown_base: str | Path,\n",
    "    bucket: Bucket,\n",
    "    prefix: str,\n",
    ") -> dict[str, Any]:\n",
    "    \"\"\"Process the first two rows in the benchmark dataset CSV and prepare model inputs.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    csv_path : str\n",
    "        Path to the CSV file containing benchmark dataset information\n",
    "    protocol_videos_base : str\n",
    "        Base path to the protocol videos directory\n",
    "    lab_notes_videos_base : str\n",
    "        Base path to the lab notes videos directory\n",
    "    markdown_base : str\n",
    "        Base path to the markdown files directory\n",
    "    bucket : object\n",
    "        The bucket object used in the prepare_all_inputs function\n",
    "    prefix : str\n",
    "        Prefix for the files in GCS bucket.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Dictionary containing all model inputs for the first two rows in the CSV,\n",
    "        with experiment names as keys\n",
    "\n",
    "    \"\"\"\n",
    "    benchmark_df = pd.read_csv(csv_path, sep=\";\")\n",
    "    unique_benchmark_df = benchmark_df[[\"protocol video\", \"protocol\"]].drop_duplicates()\n",
    "\n",
    "    all_model_inputs = {}\n",
    "\n",
    "    for (\n",
    "        _index,\n",
    "        row,\n",
    "    ) in (\n",
    "        unique_benchmark_df.iterrows()\n",
    "    ):  # for testing .head(2).iterrows() or .iloc[[13, 14]] .iloc[::2]\n",
    "        lab_video_path = Path(protocol_videos_base) / row[\"protocol video\"]\n",
    "        protocol_path = Path(markdown_base) / row[\"protocol\"]\n",
    "\n",
    "        dict_model_inputs = prepare_all_inputs(\n",
    "            lab_video_path,\n",
    "            protocol_path,\n",
    "            bucket,\n",
    "            prefix,\n",
    "        )\n",
    "\n",
    "        experiment_name = row[\"protocol\"].split(\".\")[0]\n",
    "        all_model_inputs[experiment_name] = dict_model_inputs\n",
    "\n",
    "        print(f\"Processed {experiment_name}\")\n",
    "\n",
    "    return all_model_inputs\n",
    "\n",
    "\n",
    "def prepare_knowledge(\n",
    "    folder_path: str, bucket: str, subfolder_in_bucket: str\n",
    ") -> list[Part]:\n",
    "    \"\"\"Prepare knowledge base by collecting and processing files from specified location.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    folder_path : str\n",
    "        Local folder path containing knowledge files\n",
    "    bucket : str\n",
    "        Cloud storage bucket name\n",
    "    subfolder_in_bucket : str\n",
    "        Subfolder path within the bucket\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list[Part]\n",
    "        list of Google cloud Part objects created from supported knowledge files\n",
    "\n",
    "    \"\"\"\n",
    "    knowledge_uris = video_to_protocol.collect_knowledge_uris(\n",
    "        folder_path, bucket, subfolder_in_bucket\n",
    "    )\n",
    "    knowledge = []\n",
    "    file_counts = defaultdict(int)\n",
    "\n",
    "    for file_path in knowledge_uris:\n",
    "        path_obj = Path(file_path)\n",
    "        file_ext = path_obj.suffix.lower()\n",
    "\n",
    "        if file_ext in MIME_TYPES:\n",
    "            mime_type = MIME_TYPES[file_ext]\n",
    "            try:\n",
    "                knowledge.append(Part.from_uri(file_path, mime_type=mime_type))\n",
    "                file_counts[file_ext] += 1\n",
    "            except (OSError, ValueError):\n",
    "                logger.exception(f\"Error creating Part from {file_path}\")\n",
    "        else:\n",
    "            logger.warning(f\"Unsupported file extension: {file_ext}\")\n",
    "\n",
    "    logger.info(f\"Total files processed: {len(knowledge)}\")\n",
    "    return knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_of_video_to_protocol_generation(\n",
    "    protocol_gt: str, protocol_ai: str, model_name: str, temperature: float\n",
    ") -> tuple[str, dict[str, Any], dict[str, Any]]:\n",
    "    \"\"\"Function compares an AI-generated protocol with a ground truth protocol\n",
    "    and provides detailed evaluation metrics and ratings.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    protocol_gt : str\n",
    "        Ground truth protocol used as the reference standard\n",
    "    protocol_ai : str\n",
    "        AI-generated protocol to be evaluated\n",
    "    model_name : str\n",
    "        Name of the language model to use for evaluation\n",
    "    temperature : float\n",
    "        Temperature parameter for controlling randomness in model output\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple[str, dict[str, Any], dict[str, Any]]\n",
    "        A tuple containing:\n",
    "        - evaluation (str): Detailed evaluation text with comparison analysis\n",
    "        - usage_metadata (dict): Model usage metadata from evaluation generation\n",
    "        - ratings_dict (dict): Numerical ratings for different evaluation criteria\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    evaluation, usage_metadata = generate_protocols_evaluation(\n",
    "        protocol_gt,\n",
    "        protocol_ai,\n",
    "        model_name,\n",
    "        temperature,\n",
    "    )\n",
    "\n",
    "    df_eval = eval.extract_table_to_dataframe(\n",
    "        evaluation, \"Comparative Analysis\", model_name, temperature\n",
    "    )\n",
    "\n",
    "    ratings_dict = calculate_protocol_ratings(df_eval)\n",
    "\n",
    "    return evaluation, usage_metadata, ratings_dict\n",
    "\n",
    "\n",
    "def generate_protocol_and_evaluate(\n",
    "    video: str,\n",
    "    video_example_1: str,\n",
    "    protocol_example_1: str,\n",
    "    video_example_2: str,\n",
    "    protocol_example_2: str,\n",
    "    knowledge: str,\n",
    "    model_name: str,\n",
    "    temperature: float,\n",
    "    selected_function: Callable[..., tuple[str, dict[str, Any]]],\n",
    ") -> tuple[str, dict[str, Any], dict[str, Any], dict[str, Any]]:\n",
    "    \"\"\"Generate protocol from video using selected function and evaluate the result.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    video : str\n",
    "        Input video content to generate protocol for\n",
    "    video_example_1 : str\n",
    "        First example video for few-shot learning\n",
    "    protocol_example_1 : str\n",
    "        Protocol corresponding to the first example video\n",
    "    video_example_2 : str\n",
    "        Second example video for few-shot learning\n",
    "    protocol_example_2 : str\n",
    "        Protocol corresponding to the second example video\n",
    "    knowledge : str\n",
    "        Domain-specific knowledge to incorporate in protocol generation\n",
    "    model_name : str\n",
    "        Name of the language model to use for generation and evaluation\n",
    "    temperature : float\n",
    "        Temperature parameter for controlling randomness in model output\n",
    "    selected_function : Callable[..., tuple[str, dict[str, Any]]]\n",
    "        Protocol generation function that takes video inputs and returns\n",
    "        (generated_protocol, usage_metadata)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple[str, dict[str, Any], dict[str, Any], dict[str, Any]]\n",
    "        A tuple containing:\n",
    "        - evaluation (str): Detailed evaluation text comparing generated vs ground truth\n",
    "        - ratings_dict (dict): Numerical ratings for different evaluation criteria\n",
    "        - usage_metadata_protocol_ai (dict): Model usage metadata from protocol generation\n",
    "        - usage_metadata_evaluation (dict): Model usage metadata from evaluation step\n",
    "\n",
    "    \"\"\"\n",
    "    protocol_ai, usage_metadata_protocol_ai = selected_function(\n",
    "        video,\n",
    "        video_example_1,\n",
    "        protocol_example_1,\n",
    "        video_example_2,\n",
    "        protocol_example_2,\n",
    "        knowledge,\n",
    "        model_name,\n",
    "        temperature,\n",
    "    )\n",
    "    print(\"# Generated protocol\\n\", protocol_ai)\n",
    "\n",
    "    evaluation, usage_metadata_evaluation, ratings_dict = (\n",
    "        evaluation_of_video_to_protocol_generation(\n",
    "            protocol_gt, protocol_ai, model_name, temperature\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        evaluation,\n",
    "        ratings_dict,\n",
    "        usage_metadata_protocol_ai,\n",
    "        usage_metadata_evaluation,\n",
    "    )\n",
    "\n",
    "\n",
    "def protocol_generation_without_added_knowledge(\n",
    "    video: str,\n",
    "    video_example_1: str,\n",
    "    protocol_example_1: str,\n",
    "    video_example_2: str,\n",
    "    protocol_example_2: str,\n",
    "    knowledge: str,\n",
    "    model_name: str,\n",
    "    temperature: float,\n",
    ") -> tuple[str, dict[str, Any]]:\n",
    "    \"\"\"Generate protocol using a simple prompt.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    video : str\n",
    "        Input video to generate protocol for\n",
    "    video_example_1 : str\n",
    "        First example video\n",
    "    protocol_example_1 : str\n",
    "        Protocol for first example video\n",
    "    video_example_2 : str\n",
    "        Second example video\n",
    "    protocol_example_2 : str\n",
    "        Protocol for second example video\n",
    "    knowledge : str\n",
    "        Domain knowledge to incorporate\n",
    "    model_name : str\n",
    "        Name of the model to use\n",
    "    temperature : float\n",
    "        Temperature setting for generation\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple[str, dict[str, Any]]\n",
    "        A tuple containing (protocol_ai, usage_metadata)\n",
    "\n",
    "    \"\"\"\n",
    "    inputs = [\n",
    "        \"\"\"\n",
    "    You are Professor Matthias Mann, a pioneering scientist in proteomics and mass spectrometry with extensive laboratory experience.\n",
    "    \"\"\"\n",
    "    ]\n",
    "    inputs.extend(\n",
    "        [\n",
    "            \"\"\"\n",
    "    # Instruction\n",
    "\n",
    "    You work with following input:\n",
    "    - Video: An instructional video that demonstrates how a researcher carries out a laboratory procedure.\\n\n",
    "    Your task is to analyze the provided video and to convert it into a Nature-style protocol. The goal is a clear, concise, unambiguous protocol reproducible by someone with no prior knowledge.\\n\n",
    "    Video:\n",
    "    \"\"\"\n",
    "        ]\n",
    "    )\n",
    "    inputs.extend(video)\n",
    "    inputs.extend(\n",
    "        [\n",
    "            \"\"\"\n",
    "        Protocol:\n",
    "    \"\"\"\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    protocol_ai, usage_metadata = video_to_protocol.generate_content_from_model(\n",
    "        inputs,\n",
    "        model_name,\n",
    "        temperature,\n",
    "    )\n",
    "\n",
    "    return protocol_ai, usage_metadata\n",
    "\n",
    "\n",
    "def protocol_generation_with_examples(\n",
    "    video: str,\n",
    "    video_example_1: str,\n",
    "    protocol_example_1: str,\n",
    "    video_example_2: str,\n",
    "    protocol_example_2: str,\n",
    "    knowledge: str,\n",
    "    model_name: str,\n",
    "    temperature: float,\n",
    ") -> tuple[str, dict[str, Any]]:\n",
    "    \"\"\"Generate protocol using examples.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    video : str\n",
    "        Input video to generate protocol for\n",
    "    video_example_1 : str\n",
    "        First example video\n",
    "    protocol_example_1 : str\n",
    "        Protocol for first example video\n",
    "    video_example_2 : str\n",
    "        Second example video\n",
    "    protocol_example_2 : str\n",
    "        Protocol for second example video\n",
    "    knowledge : str\n",
    "        Domain knowledge to incorporate\n",
    "    model_name : str\n",
    "        Name of the model to use\n",
    "    temperature : float\n",
    "        Temperature setting for generation\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple[str, dict[str, Any]]\n",
    "        A tuple containing (protocol_ai, usage_metadata)\n",
    "\n",
    "    \"\"\"\n",
    "    inputs = [\n",
    "        \"\"\"\n",
    "    You are Professor Matthias Mann, a pioneering scientist in proteomics and mass spectrometry with extensive laboratory experience.\n",
    "    \"\"\"\n",
    "    ]\n",
    "    inputs.extend(\n",
    "        [\n",
    "            \"\"\"\n",
    "    # Instruction\n",
    "\n",
    "    You work with following input:\n",
    "    - Video: An instructional video that demonstrates how a researcher carries out a laboratory procedure.\\n\n",
    "    Your task is to analyze the provided video and to convert it into a Nature-style protocol. The goal is a clear, concise, unambiguous protocol reproducible by someone with no prior knowledge.\n",
    "    \"\"\"\n",
    "        ]\n",
    "    )\n",
    "    inputs.extend(\n",
    "        [\n",
    "            \"\"\"\n",
    "        # ====== EXAMPLE (FOR REFERENCE ONLY) ======\\n\n",
    "        The following set of videos and resulting protocols should solely serve as an example and are not part of the task.\\n\n",
    "        Example Video 1:\n",
    "        \"\"\"\n",
    "        ]\n",
    "    )\n",
    "    inputs.extend(video_example_1)\n",
    "    inputs.extend(\n",
    "        [\n",
    "            \"\"\"Example documentation 1:\n",
    "    1. Describe what you can hear with timestamps:\n",
    "    - No audible speech.\\n\n",
    "    2. Describe what you can see with timestamps:\n",
    "    - 0:00-0:05 The camera pans around the back of a timsTOF mass spectrometer in a lab. A bench with various equipment is visible.\n",
    "    - 0:06-0:26 A researcher takes an Eppendorf pipette, then setting volume to 1 uL.\n",
    "    - 0:27-0:30 The researcher indicates that the color on the top of a pipette and of pipette tip box have to agree.\n",
    "    - 0:31-0:35 the researcher attaches a pipette tip to the pipette.\n",
    "    - 0:36-0:50 The researcher opens an eppendorf vial and aspirates the content.\n",
    "    - 0:51-0:54 The camera moves to show the lab and the evosep instrument connected to the mass spectrometer.\n",
    "    - 0:55-1:03 The researcher disconnects a tubing on the ultraSource.\n",
    "    - 1:03-1:07 The researcher pipettes liquid into the fitting connecting the UltraSource of a mass spectrometer.\n",
    "    - 1:07-1:08 The researcher closes conencts the tubing and fitting again.\n",
    "    - 1:09-1:11 The camera focused on evosep and mass spectrometer connection.\n",
    "    - 1:11-1:14 The researcher is removing the pipette tip into a wast container.\n",
    "    - 1:15-1:17 The camera move far away from the evosep and the mass spectrometer.\n",
    "\n",
    "    3. Describe the used equipment:\n",
    "    - timsTOF mass spectrometer: Dark blue.\n",
    "    - Evosep One LC system: Orange and gray.\n",
    "    - Eppendorf pipette: White.\n",
    "    - Pipette tips: Transparent with dark grey top.\n",
    "    - Eppendorf tubes: Small clear plastic vials.\n",
    "    - Various bottles and consumables on the lab bench.\n",
    "    \"\"\"\n",
    "        ]\n",
    "    )\n",
    "    inputs.extend([\"Example Protocol 1:\"])\n",
    "    inputs.extend(protocol_example_1)\n",
    "    inputs.extend([\"Example Video 2:\"])\n",
    "    inputs.extend(video_example_2)\n",
    "    inputs.extend(\n",
    "        [\n",
    "            \"\"\"Example documentation 2:\n",
    "    1. Describe what you can hear with timestamps:\n",
    "    - 0:00 - 0:08: \"Hello, here I will show you how to reset the TIMS Control perspective. At the moment, it's not in the default state. This can be seen at this image which stands out.\"\n",
    "    - 0:09 - 0:14: \"For this, we click here at the middle and say reset perspective.\"\n",
    "    - 0:15 - 0:16: \"Yes, we want this.\"\n",
    "    - 0:17 - 0:21: \"Now we're back to the default view.\"\\n\n",
    "    2. Describe what you can see with timestamps:\n",
    "    - 0:00 - 0:05: The screen displays the Bruker timsControl software interface. The window title indicates \"timsTOFscp\". Several panels are visible: \"TIMS View\" at the top left showing a 2D plot (likely ion mobility vs. m/z), a \"Chromatogram View\" prominently on the right side displaying two traces (green and red), and various instrument status indicators on the left (Automation, HyStar, Calibration, Vacuum).\n",
    "    - 0:05 - 0:08: The narrator refers to the current layout as non-default, implying the position of the \"Chromatogram View\" is non-standard and an customized arrangement.\n",
    "    - 0:08 - 0:11: The mouse cursor moves to the top-right of the software window, towards a set of icons. It hovers over an icon that looks like two overlapping rectangles, typically used for managing window layouts or perspectives.\n",
    "    - 0:11 - 0:12: The mouse clicks on the perspective management icon. A dropdown menu appears with options including \"Show View...\", \"Save Perspective As...\", \"Reset Perspective...\", \"Home\", \"Method Editor\", \"Maintenance\", and \"Monitoring\".\n",
    "    - 0:12 - 0:14: The mouse cursor moves down the dropdown menu and selects \"Reset Perspective...\".\n",
    "    - 0:14 - 0:15: A confirmation dialog box titled \"Reset Perspective\" pops up, asking: \"Do you want to reset the current 'Home' perspective to its defaults?\". \"Yes\" and \"No\" buttons are presented.\n",
    "    - 0:15 - 0:16: The mouse cursor clicks the \"Yes\" button in the confirmation dialog.\n",
    "    - 0:17 - 0:21: The software interface panels dynamically rearrange. The \"TIMS View\" remains at the top. A \"Spectrum View\" now appears in the middle section, and the \"Chromatogram View\" is repositioned to the bottom of the main display area. This is indicative of the default layout for this software.\n",
    "    - 0:21 - 0:23: The software is shown in its new, reset (default) perspective. The mouse cursor makes a brief circular movement over the \"Source\" and \"Syringe Pump\" control area in the lower part of the screen before the video ends.\\n\n",
    "    3. Describe the used equipment:\n",
    "    - Bruker timsControl Software: The primary focus of the video. The window title \"timsTOFscp - ... - timsControl\" indicates this specific software, used for controlling Bruker TIMS-TOF series mass spectrometers.\n",
    "    - Computer System: The software is running on a computer, evidenced by the VNC Viewer window frame and the Windows taskbar visible at the very bottom of the screen.\n",
    "    - (Implied) Bruker timsTOF Mass Spectrometer: The software is designed to control a Trapped Ion Mobility Spectrometry Time-Of-Flight mass spectrometer (e.g., timsTOF Pro, timsTOF SCP, timsTOF fleX). The \"TIMS View\" and other parameters are specific to such instrumentation.\n",
    "    \"\"\"\n",
    "        ]\n",
    "    )\n",
    "    inputs.extend([\"Example Protocol:\"])\n",
    "    inputs.extend(protocol_example_2)\n",
    "    inputs.extend(\n",
    "        [\n",
    "            \"\"\"\n",
    "        # ====== Beginn of Analysis Task ======\\n\n",
    "        ## Important: The analysis must be performed on the following video \\n\n",
    "        Video:\n",
    "        \"\"\"\n",
    "        ]\n",
    "    )\n",
    "    inputs.extend(video)\n",
    "    inputs.extend(\n",
    "        [\n",
    "            \"\"\"\n",
    "        Protocol:\n",
    "    \"\"\"\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    protocol_ai, usage_metadata = video_to_protocol.generate_content_from_model(\n",
    "        inputs,\n",
    "        model_name,\n",
    "        temperature,\n",
    "    )\n",
    "\n",
    "    return protocol_ai, usage_metadata\n",
    "\n",
    "\n",
    "def protocol_generation_with_thinking_step_by_step(\n",
    "    video: str,\n",
    "    video_example_1: str,\n",
    "    protocol_example_1: str,\n",
    "    video_example_2: str,\n",
    "    protocol_example_2: str,\n",
    "    knowledge: str,\n",
    "    model_name: str,\n",
    "    temperature: float,\n",
    ") -> tuple[str, dict[str, Any]]:\n",
    "    \"\"\"Generate protocol using step-by-step thinking.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    video : str\n",
    "        Input video to generate protocol for\n",
    "    video_example_1 : str\n",
    "        First example video\n",
    "    protocol_example_1 : str\n",
    "        Protocol for first example video\n",
    "    video_example_2 : str\n",
    "        Second example video\n",
    "    protocol_example_2 : str\n",
    "        Protocol for second example video\n",
    "    knowledge : str\n",
    "        Domain knowledge to incorporate\n",
    "    model_name : str\n",
    "        Name of the model to use\n",
    "    temperature : float\n",
    "        Temperature setting for generation\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple[str, dict[str, Any]]\n",
    "        A tuple containing (protocol_ai, usage_metadata)\n",
    "\n",
    "    \"\"\"\n",
    "    inputs = [\n",
    "        \"\"\"\n",
    "    You are Professor Matthias Mann, a pioneering scientist in proteomics and mass spectrometry with extensive laboratory experience.\n",
    "    \"\"\"\n",
    "    ]\n",
    "    inputs.extend(\n",
    "        [\n",
    "            \"\"\"\n",
    "    # Instruction\n",
    "\n",
    "    You work with following input:\n",
    "    - Video: An instructional video that demonstrates how a researcher carries out a laboratory procedure.\\n\n",
    "    Your task is to analyze the provided video and to convert it into a Nature-style protocol. The goal is a clear, concise, unambiguous protocol reproducible by someone with no prior knowledge.\\n\n",
    "    ## Follow this structured approach:\n",
    "    * Step 1: Go through the 'Video' completely from beginning to end.\n",
    "    * Step 2: Document all observations:\n",
    "        - write down what you can hear with timestamps\n",
    "        - write down all actions you can see with timestamps\n",
    "        - note down the equipment you can identify\n",
    "    * Step 3: Convert your observations into a Nature-style protocol:\n",
    "        ###Protocol Writing Guidelines\n",
    "        ####Format Requirements\n",
    "        1. Title (format: **# Title**)\n",
    "        2. Abstract (format: **## Abstract** followed by a paragraph)\n",
    "        3. Materials section with Equipment and Reagents subsections\n",
    "            (format: **## Materials**\n",
    "                    **### Equipment**\n",
    "                    - **Item 1**\n",
    "                    - **Item 2**)\n",
    "        4. Procedure with estimated timing\n",
    "            (format: **## Procedure**\n",
    "                    *Estimated timing: X minutes*\n",
    "                    1. Step one\n",
    "                    2. Step two)\n",
    "        5. Expected Results section (format: **## Expected Results**)\n",
    "        6. Figures section (format: **## Figures**)\n",
    "        7. References section (format: **## References**)\n",
    "\n",
    "        ###Key Content Adjustments\n",
    "        #### Abstract\n",
    "        - Focus on the core procedure, not extensive background\n",
    "\n",
    "        #### Procedure Section\n",
    "        - Steps:\n",
    "            - Focus on essential actions only.\n",
    "            - Be brief in your description.\n",
    "            - Give every step its own number.\n",
    "            - Use subheadings to group steps such as\n",
    "                '### Switch timsTOF to standby\n",
    "                1. In ...\n",
    "                2. Verified ...\n",
    "                3. In ...\n",
    "                ...'\n",
    "        - Language: Use direct, action-oriented language with commonly used vocabularies\n",
    "        - Estimated timing: Use the video legth\n",
    "    \"\"\"\n",
    "        ]\n",
    "    )\n",
    "    inputs.extend(\n",
    "        [\n",
    "            \"\"\"\n",
    "        # ====== EXAMPLE (FOR REFERENCE ONLY) ======\\n\n",
    "        The following set of videos and resulting protocols should solely serve as an example and are not part of the task.\\n\n",
    "        Example Video 1:\n",
    "        \"\"\"\n",
    "        ]\n",
    "    )\n",
    "    inputs.extend(video_example_1)\n",
    "    inputs.extend(\n",
    "        [\n",
    "            \"\"\"Example documentation 1:\n",
    "    1. Describe what you can hear with timestamps:\n",
    "    - No audible speech.\\n\n",
    "    2. Describe what you can see with timestamps:\n",
    "    - 0:00-0:05 The camera pans around the back of a timsTOF mass spectrometer in a lab. A bench with various equipment is visible.\n",
    "    - 0:06-0:26 A researcher takes an Eppendorf pipette, then setting volume to 1 uL.\n",
    "    - 0:27-0:30 The researcher indicates that the color on the top of a pipette and of pipette tip box have to agree.\n",
    "    - 0:31-0:35 the researcher attaches a pipette tip to the pipette.\n",
    "    - 0:36-0:50 The researcher opens an eppendorf vial and aspirates the content.\n",
    "    - 0:51-0:54 The camera moves to show the lab and the evosep instrument connected to the mass spectrometer.\n",
    "    - 0:55-1:03 The researcher disconnects a tubing on the ultraSource.\n",
    "    - 1:03-1:07 The researcher pipettes liquid into the fitting connecting the UltraSource of a mass spectrometer.\n",
    "    - 1:07-1:08 The researcher closes conencts the tubing and fitting again.\n",
    "    - 1:09-1:11 The camera focused on evosep and mass spectrometer connection.\n",
    "    - 1:11-1:14 The researcher is removing the pipette tip into a wast container.\n",
    "    - 1:15-1:17 The camera move far away from the evosep and the mass spectrometer.\\n\n",
    "    3. Describe the used equipment:\n",
    "    - timsTOF mass spectrometer: Dark blue.\n",
    "    - Evosep One LC system: Orange and gray.\n",
    "    - Eppendorf pipette: White.\n",
    "    - Pipette tips: Transparent with dark grey top.\n",
    "    - Eppendorf tubes: Small clear plastic vials.\n",
    "    - Various bottles and consumables on the lab bench.\n",
    "    \"\"\"\n",
    "        ]\n",
    "    )\n",
    "    inputs.extend([\"Example Protocol 1:\"])\n",
    "    inputs.extend(protocol_example_1)\n",
    "    inputs.extend([\"Example Video 2:\"])\n",
    "    inputs.extend(video_example_2)\n",
    "    inputs.extend(\n",
    "        [\n",
    "            \"\"\"Example documentation 2:\n",
    "    1. Describe what you can hear with timestamps:\n",
    "    - 0:00 - 0:08: \"Hello, here I will show you how to reset the TIMS Control perspective. At the moment, it's not in the default state. This can be seen at this image which stands out.\"\n",
    "    - 0:09 - 0:14: \"For this, we click here at the middle and say reset perspective.\"\n",
    "    - 0:15 - 0:16: \"Yes, we want this.\"\n",
    "    - 0:17 - 0:21: \"Now we're back to the default view.\"\\n\n",
    "    2. Describe what you can see with timestamps:\n",
    "    - 0:00 - 0:05: The screen displays the Bruker timsControl software interface. The window title indicates \"timsTOFscp\". Several panels are visible: \"TIMS View\" at the top left showing a 2D plot (likely ion mobility vs. m/z), a \"Chromatogram View\" prominently on the right side displaying two traces (green and red), and various instrument status indicators on the left (Automation, HyStar, Calibration, Vacuum).\n",
    "    - 0:05 - 0:08: The narrator refers to the current layout as non-default, implying the position of the \"Chromatogram View\" is non-standard and an customized arrangement.\n",
    "    - 0:08 - 0:11: The mouse cursor moves to the top-right of the software window, towards a set of icons. It hovers over an icon that looks like two overlapping rectangles, typically used for managing window layouts or perspectives.\n",
    "    - 0:11 - 0:12: The mouse clicks on the perspective management icon. A dropdown menu appears with options including \"Show View...\", \"Save Perspective As...\", \"Reset Perspective...\", \"Home\", \"Method Editor\", \"Maintenance\", and \"Monitoring\".\n",
    "    - 0:12 - 0:14: The mouse cursor moves down the dropdown menu and selects \"Reset Perspective...\".\n",
    "    - 0:14 - 0:15: A confirmation dialog box titled \"Reset Perspective\" pops up, asking: \"Do you want to reset the current 'Home' perspective to its defaults?\". \"Yes\" and \"No\" buttons are presented.\n",
    "    - 0:15 - 0:16: The mouse cursor clicks the \"Yes\" button in the confirmation dialog.\n",
    "    - 0:17 - 0:21: The software interface panels dynamically rearrange. The \"TIMS View\" remains at the top. A \"Spectrum View\" now appears in the middle section, and the \"Chromatogram View\" is repositioned to the bottom of the main display area. This is indicative of the default layout for this software.\n",
    "    - 0:21 - 0:23: The software is shown in its new, reset (default) perspective. The mouse cursor makes a brief circular movement over the \"Source\" and \"Syringe Pump\" control area in the lower part of the screen before the video ends.\\n\n",
    "    3. Describe the used equipment:\n",
    "    - Bruker timsControl Software: The primary focus of the video. The window title \"timsTOFscp - ... - timsControl\" indicates this specific software, used for controlling Bruker TIMS-TOF series mass spectrometers.\n",
    "    - Computer System: The software is running on a computer, evidenced by the VNC Viewer window frame and the Windows taskbar visible at the very bottom of the screen.\n",
    "    - (Implied) Bruker timsTOF Mass Spectrometer: The software is designed to control a Trapped Ion Mobility Spectrometry Time-Of-Flight mass spectrometer (e.g., timsTOF Pro, timsTOF SCP, timsTOF fleX). The \"TIMS View\" and other parameters are specific to such instrumentation.\n",
    "    \"\"\"\n",
    "        ]\n",
    "    )\n",
    "    inputs.extend([\"Example Protocol:\"])\n",
    "    inputs.extend(protocol_example_2)\n",
    "    inputs.extend(\n",
    "        [\n",
    "            \"\"\"\n",
    "        # ====== Beginn of Analysis Task ======\\n\n",
    "        ## Important: The analysis must be performed on the following video \\n\n",
    "        Video:\n",
    "        \"\"\"\n",
    "        ]\n",
    "    )\n",
    "    inputs.extend(video)\n",
    "    inputs.extend(\n",
    "        [\n",
    "            \"\"\"\n",
    "        Protocol:\n",
    "    \"\"\"\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    protocol_ai, usage_metadata = video_to_protocol.generate_content_from_model(\n",
    "        inputs,\n",
    "        model_name,\n",
    "        temperature,\n",
    "    )\n",
    "\n",
    "    return protocol_ai, usage_metadata\n",
    "\n",
    "\n",
    "def protocol_generation_with_thinking_step_by_step_plus_knowledge(\n",
    "    video: str,\n",
    "    video_example_1: str,\n",
    "    protocol_example_1: str,\n",
    "    video_example_2: str,\n",
    "    protocol_example_2: str,\n",
    "    knowledge: str,\n",
    "    model_name: str,\n",
    "    temperature: float,\n",
    ") -> tuple[str, dict[str, Any]]:\n",
    "    \"\"\"Generate protocol using step-by-step thinking with knowledge.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    video : str\n",
    "        Input video to generate protocol for\n",
    "    video_example_1 : str\n",
    "        First example video\n",
    "    protocol_example_1 : str\n",
    "        Protocol for first example video\n",
    "    video_example_2 : str\n",
    "        Second example video\n",
    "    protocol_example_2 : str\n",
    "        Protocol for second example video\n",
    "    knowledge : str\n",
    "        Domain knowledge to incorporate\n",
    "    model_name : str\n",
    "        Name of the model to use\n",
    "    temperature : float\n",
    "        Temperature setting for generation\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple[str, dict[str, Any]]\n",
    "        A tuple containing (protocol_ai, usage_metadata)\n",
    "\n",
    "    \"\"\"\n",
    "    inputs = [\n",
    "        \"\"\"\n",
    "    You are Professor Matthias Mann, a pioneering scientist in proteomics and mass spectrometry with extensive laboratory experience.\\n\n",
    "    ## ====== Background Knowledge (FOR REFERENCE ONLY) ======\n",
    "    [These documents are for building your proteomics background knowledge and are not part of your task.]\n",
    "    \"\"\"\n",
    "    ]\n",
    "    inputs.extend(knowledge)\n",
    "    inputs.extend(\n",
    "        [\n",
    "            \"\"\"\n",
    "    # Instruction\n",
    "\n",
    "    You work with following input:\n",
    "    - Video: An instructional video that demonstrates how a researcher carries out a laboratory procedure.\\n\n",
    "    Your task is to analyze the provided video and to convert it into a Nature-style protocol. The goal is a clear, concise, unambiguous protocol reproducible by someone with no prior knowledge.\\n\n",
    "    ## Follow this structured approach:\n",
    "    * Step 1: Go through the 'Video' completely from beginning to end.\n",
    "    * Step 2: Document all observations:\n",
    "        - write down what you can hear with timestamps\n",
    "        - write down all actions you can see with timestamps\n",
    "        - note down the equipment you can identify\n",
    "    * Step 3: Convert your observations into a Nature-style protocol:\n",
    "        ###Protocol Writing Guidelines\n",
    "        ####Format Requirements\n",
    "        1. Title (format: **# Title**)\n",
    "        2. Abstract (format: **## Abstract** followed by a paragraph)\n",
    "        3. Materials section with Equipment and Reagents subsections\n",
    "            (format: **## Materials**\n",
    "                    **### Equipment**\n",
    "                    - **Item 1**\n",
    "                    - **Item 2**)\n",
    "        4. Procedure with estimated timing\n",
    "            (format: **## Procedure**\n",
    "                    *Estimated timing: X minutes*\n",
    "                    1. Step one\n",
    "                    2. Step two)\n",
    "        5. Expected Results section (format: **## Expected Results**)\n",
    "        6. Figures section (format: **## Figures**)\n",
    "        7. References section (format: **## References**)\n",
    "\n",
    "        ###Key Content Adjustments\n",
    "        #### Abstract\n",
    "        - Focus on the core procedure, not extensive background\n",
    "\n",
    "        #### Procedure Section\n",
    "        - Steps:\n",
    "            - Focus on essential actions only.\n",
    "            - Be brief in your description.\n",
    "            - Give every step its own number.\n",
    "            - Use subheadings to group steps such as\n",
    "                '### Switch timsTOF to standby\n",
    "                1. In ...\n",
    "                2. Verified ...\n",
    "                3. In ...\n",
    "                ...'\n",
    "        - Language: Use direct, action-oriented language with commonly used vocabularies\n",
    "        - Estimated timing: Use the video legth\n",
    "    \"\"\"\n",
    "        ]\n",
    "    )\n",
    "    inputs.extend(\n",
    "        [\n",
    "            \"\"\"\n",
    "        # ====== EXAMPLE (FOR REFERENCE ONLY) ======\\n\n",
    "        The following set of videos and resulting protocols should solely serve as an example and are not part of the task.\\n\n",
    "        Example Video 1:\n",
    "        \"\"\"\n",
    "        ]\n",
    "    )\n",
    "    inputs.extend(video_example_1)\n",
    "    inputs.extend(\n",
    "        [\n",
    "            \"\"\"Example documentation 1:\n",
    "    1. Describe what you can hear with timestamps:\n",
    "    - No audible speech.\\n\n",
    "    2. Describe what you can see with timestamps:\n",
    "    - 0:00-0:05 The camera pans around the back of a timsTOF mass spectrometer in a lab. A bench with various equipment is visible.\n",
    "    - 0:06-0:26 A researcher takes an Eppendorf pipette, then setting volume to 1 uL.\n",
    "    - 0:27-0:30 The researcher indicates that the color on the top of a pipette and of pipette tip box have to agree.\n",
    "    - 0:31-0:35 the researcher attaches a pipette tip to the pipette.\n",
    "    - 0:36-0:50 The researcher opens an eppendorf vial and aspirates the content.\n",
    "    - 0:51-0:54 The camera moves to show the lab and the evosep instrument connected to the mass spectrometer.\n",
    "    - 0:55-1:03 The researcher disconnects a tubing on the ultraSource.\n",
    "    - 1:03-1:07 The researcher pipettes liquid into the fitting connecting the UltraSource of a mass spectrometer.\n",
    "    - 1:07-1:08 The researcher closes conencts the tubing and fitting again.\n",
    "    - 1:09-1:11 The camera focused on evosep and mass spectrometer connection.\n",
    "    - 1:11-1:14 The researcher is removing the pipette tip into a wast container.\n",
    "    - 1:15-1:17 The camera move far away from the evosep and the mass spectrometer.\\n\n",
    "    3. Describe the used equipment:\n",
    "    - timsTOF mass spectrometer: Dark blue.\n",
    "    - Evosep One LC system: Orange and gray.\n",
    "    - Eppendorf pipette: White.\n",
    "    - Pipette tips: Transparent with dark grey top.\n",
    "    - Eppendorf tubes: Small clear plastic vials.\n",
    "    - Various bottles and consumables on the lab bench.\n",
    "    \"\"\"\n",
    "        ]\n",
    "    )\n",
    "    inputs.extend([\"Example Protocol 1:\"])\n",
    "    inputs.extend(protocol_example_1)\n",
    "    inputs.extend([\"Example Video 2:\"])\n",
    "    inputs.extend(video_example_2)\n",
    "    inputs.extend(\n",
    "        [\n",
    "            \"\"\"Example documentation 2:\n",
    "    1. Describe what you can hear with timestamps:\n",
    "    - 0:00 - 0:08: \"Hello, here I will show you how to reset the TIMS Control perspective. At the moment, it's not in the default state. This can be seen at this image which stands out.\"\n",
    "    - 0:09 - 0:14: \"For this, we click here at the middle and say reset perspective.\"\n",
    "    - 0:15 - 0:16: \"Yes, we want this.\"\n",
    "    - 0:17 - 0:21: \"Now we're back to the default view.\"\\n\n",
    "    2. Describe what you can see with timestamps:\n",
    "    - 0:00 - 0:05: The screen displays the Bruker timsControl software interface. The window title indicates \"timsTOFscp\". Several panels are visible: \"TIMS View\" at the top left showing a 2D plot (likely ion mobility vs. m/z), a \"Chromatogram View\" prominently on the right side displaying two traces (green and red), and various instrument status indicators on the left (Automation, HyStar, Calibration, Vacuum).\n",
    "    - 0:05 - 0:08: The narrator refers to the current layout as non-default, implying the position of the \"Chromatogram View\" is non-standard and an customized arrangement.\n",
    "    - 0:08 - 0:11: The mouse cursor moves to the top-right of the software window, towards a set of icons. It hovers over an icon that looks like two overlapping rectangles, typically used for managing window layouts or perspectives.\n",
    "    - 0:11 - 0:12: The mouse clicks on the perspective management icon. A dropdown menu appears with options including \"Show View...\", \"Save Perspective As...\", \"Reset Perspective...\", \"Home\", \"Method Editor\", \"Maintenance\", and \"Monitoring\".\n",
    "    - 0:12 - 0:14: The mouse cursor moves down the dropdown menu and selects \"Reset Perspective...\".\n",
    "    - 0:14 - 0:15: A confirmation dialog box titled \"Reset Perspective\" pops up, asking: \"Do you want to reset the current 'Home' perspective to its defaults?\". \"Yes\" and \"No\" buttons are presented.\n",
    "    - 0:15 - 0:16: The mouse cursor clicks the \"Yes\" button in the confirmation dialog.\n",
    "    - 0:17 - 0:21: The software interface panels dynamically rearrange. The \"TIMS View\" remains at the top. A \"Spectrum View\" now appears in the middle section, and the \"Chromatogram View\" is repositioned to the bottom of the main display area. This is indicative of the default layout for this software.\n",
    "    - 0:21 - 0:23: The software is shown in its new, reset (default) perspective. The mouse cursor makes a brief circular movement over the \"Source\" and \"Syringe Pump\" control area in the lower part of the screen before the video ends.\\n\n",
    "    3. Describe the used equipment:\n",
    "    - Bruker timsControl Software: The primary focus of the video. The window title \"timsTOFscp - ... - timsControl\" indicates this specific software, used for controlling Bruker TIMS-TOF series mass spectrometers.\n",
    "    - Computer System: The software is running on a computer, evidenced by the VNC Viewer window frame and the Windows taskbar visible at the very bottom of the screen.\n",
    "    - (Implied) Bruker timsTOF Mass Spectrometer: The software is designed to control a Trapped Ion Mobility Spectrometry Time-Of-Flight mass spectrometer (e.g., timsTOF Pro, timsTOF SCP, timsTOF fleX). The \"TIMS View\" and other parameters are specific to such instrumentation.\n",
    "    \"\"\"\n",
    "        ]\n",
    "    )\n",
    "    inputs.extend([\"Example Protocol:\"])\n",
    "    inputs.extend(protocol_example_2)\n",
    "    inputs.extend(\n",
    "        [\n",
    "            \"\"\"\n",
    "        # ====== Beginn of Analysis Task ======\\n\n",
    "        ## Important: The analysis must be performed on the following video \\n\n",
    "        Video:\n",
    "        \"\"\"\n",
    "        ]\n",
    "    )\n",
    "    inputs.extend(video)\n",
    "    inputs.extend(\n",
    "        [\n",
    "            \"\"\"\n",
    "        Protocol:\n",
    "    \"\"\"\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    protocol_ai, usage_metadata = video_to_protocol.generate_content_from_model(\n",
    "        inputs,\n",
    "        model_name,\n",
    "        temperature,\n",
    "    )\n",
    "\n",
    "    return protocol_ai, usage_metadata\n",
    "\n",
    "\n",
    "def protocol_generation_with_thinking_step_by_step_plus_knowledge_without_persona(\n",
    "    video: str,\n",
    "    video_example_1: str,\n",
    "    protocol_example_1: str,\n",
    "    video_example_2: str,\n",
    "    protocol_example_2: str,\n",
    "    knowledge: str,\n",
    "    model_name: str,\n",
    "    temperature: float,\n",
    ") -> tuple[str, dict[str, Any]]:\n",
    "    \"\"\"Generate protocol using step-by-step thinking with knowledge but without persona.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    video : str\n",
    "        Input video to generate protocol for\n",
    "    video_example_1 : str\n",
    "        First example video\n",
    "    protocol_example_1 : str\n",
    "        Protocol for first example video\n",
    "    video_example_2 : str\n",
    "        Second example video\n",
    "    protocol_example_2 : str\n",
    "        Protocol for second example video\n",
    "    knowledge : str\n",
    "        Domain knowledge to incorporate\n",
    "    model_name : str\n",
    "        Name of the model to use\n",
    "    temperature : float\n",
    "        Temperature setting for generation\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple[str, dict[str, Any]]\n",
    "        A tuple containing (protocol_ai, usage_metadata)\n",
    "\n",
    "    \"\"\"\n",
    "    inputs = [\n",
    "        \"\"\"\n",
    "    ## ====== Background Knowledge (FOR REFERENCE ONLY) ======\n",
    "    [These documents are for building your proteomics background knowledge and are not part of your task.]\n",
    "    \"\"\"\n",
    "    ]\n",
    "    inputs.extend(knowledge)\n",
    "    inputs.extend(\n",
    "        [\n",
    "            \"\"\"\n",
    "    # Instruction\n",
    "\n",
    "    You work with following input:\n",
    "    - Video: An instructional video that demonstrates how a researcher carries out a laboratory procedure.\\n\n",
    "    Your task is to analyze the provided video and to convert it into a Nature-style protocol. The goal is a clear, concise, unambiguous protocol reproducible by someone with no prior knowledge.\\n\n",
    "    ## Follow this structured approach:\n",
    "    * Step 1: Go through the 'Video' completely from beginning to end.\n",
    "    * Step 2: Document all observations:\n",
    "        - write down what you can hear with timestamps\n",
    "        - write down all actions you can see with timestamps\n",
    "        - note down the equipment you can identify\n",
    "    * Step 3: Convert your observations into a Nature-style protocol:\n",
    "        ###Protocol Writing Guidelines\n",
    "        ####Format Requirements\n",
    "        1. Title (format: **# Title**)\n",
    "        2. Abstract (format: **## Abstract** followed by a paragraph)\n",
    "        3. Materials section with Equipment and Reagents subsections\n",
    "            (format: **## Materials**\n",
    "                    **### Equipment**\n",
    "                    - **Item 1**\n",
    "                    - **Item 2**)\n",
    "        4. Procedure with estimated timing\n",
    "            (format: **## Procedure**\n",
    "                    *Estimated timing: X minutes*\n",
    "                    1. Step one\n",
    "                    2. Step two)\n",
    "        5. Expected Results section (format: **## Expected Results**)\n",
    "        6. Figures section (format: **## Figures**)\n",
    "        7. References section (format: **## References**)\n",
    "\n",
    "        ###Key Content Adjustments\n",
    "        #### Abstract\n",
    "        - Focus on the core procedure, not extensive background\n",
    "\n",
    "        #### Procedure Section\n",
    "        - Steps:\n",
    "            - Focus on essential actions only.\n",
    "            - Be brief in your description.\n",
    "            - Give every step its own number.\n",
    "            - Use subheadings to group steps such as\n",
    "                '### Switch timsTOF to standby\n",
    "                1. In ...\n",
    "                2. Verified ...\n",
    "                3. In ...\n",
    "                ...'\n",
    "        - Language: Use direct, action-oriented language with commonly used vocabularies\n",
    "        - Estimated timing: Use the video legth\n",
    "    \"\"\"\n",
    "        ]\n",
    "    )\n",
    "    inputs.extend(\n",
    "        [\n",
    "            \"\"\"\n",
    "        # ====== EXAMPLE (FOR REFERENCE ONLY) ======\\n\n",
    "        The following set of videos and resulting protocols should solely serve as an example and are not part of the task.\\n\n",
    "        Example Video 1:\n",
    "        \"\"\"\n",
    "        ]\n",
    "    )\n",
    "    inputs.extend(video_example_1)\n",
    "    inputs.extend(\n",
    "        [\n",
    "            \"\"\"Example documentation 1:\n",
    "    1. Describe what you can hear with timestamps:\n",
    "    - No audible speech.\\n\n",
    "    2. Describe what you can see with timestamps:\n",
    "    - 0:00-0:05 The camera pans around the back of a timsTOF mass spectrometer in a lab. A bench with various equipment is visible.\n",
    "    - 0:06-0:26 A researcher takes an Eppendorf pipette, then setting volume to 1 uL.\n",
    "    - 0:27-0:30 The researcher indicates that the color on the top of a pipette and of pipette tip box have to agree.\n",
    "    - 0:31-0:35 the researcher attaches a pipette tip to the pipette\n",
    "    - 0:36-0:50 The researcher opens an eppendorf vial and aspirates the content.\n",
    "    - 0:51-0:54 The camera moves to show the lab and the evosep instrument connected to the mass spectrometer.\n",
    "    - 0:55-1:03 The researcher disconnects a tubing on the ultraSource.\n",
    "    - 1:03-1:07 The researcher pipettes liquid into the fitting connecting the UltraSource of a mass spectrometer.\n",
    "    - 1:07-1:08 The researcher closes conencts the tubing and fitting again.\n",
    "    - 1:09-1:11 The camera focused on evosep and mass spectrometer connection.\n",
    "    - 1:11-1:14 The researcher is removing the pipette tip into a wast container.\n",
    "    - 1:15-1:17 The camera move far away from the evosep and the mass spectrometer.\\n\n",
    "    3. Describe the used equipment:\n",
    "    - timsTOF mass spectrometer: Dark blue.\n",
    "    - Evosep One LC system: Orange and gray.\n",
    "    - Eppendorf pipette: White.\n",
    "    - Pipette tips: Transparent with dark grey top.\n",
    "    - Eppendorf tubes: Small clear plastic vials.\n",
    "    - Various bottles and consumables on the lab bench.\n",
    "    \"\"\"\n",
    "        ]\n",
    "    )\n",
    "    inputs.extend([\"Example Protocol 1:\"])\n",
    "    inputs.extend(protocol_example_1)\n",
    "    inputs.extend([\"Example Video 2:\"])\n",
    "    inputs.extend(video_example_2)\n",
    "    inputs.extend(\n",
    "        [\n",
    "            \"\"\"Example documentation 2:\n",
    "    1. Describe what you can hear with timestamps:\n",
    "    - 0:00 - 0:08: \"Hello, here I will show you how to reset the TIMS Control perspective. At the moment, it's not in the default state. This can be seen at this image which stands out.\"\n",
    "    - 0:09 - 0:14: \"For this, we click here at the middle and say reset perspective.\"\n",
    "    - 0:15 - 0:16: \"Yes, we want this.\"\n",
    "    - 0:17 - 0:21: \"Now we're back to the default view.\"\\n\n",
    "    2. Describe what you can see with timestamps:\n",
    "    - 0:00 - 0:05: The screen displays the Bruker timsControl software interface. The window title indicates \"timsTOFscp\". Several panels are visible: \"TIMS View\" at the top left showing a 2D plot (likely ion mobility vs. m/z), a \"Chromatogram View\" prominently on the right side displaying two traces (green and red), and various instrument status indicators on the left (Automation, HyStar, Calibration, Vacuum).\n",
    "    - 0:05 - 0:08: The narrator refers to the current layout as non-default, implying the position of the \"Chromatogram View\" is non-standard and an customized arrangement.\n",
    "    - 0:08 - 0:11: The mouse cursor moves to the top-right of the software window, towards a set of icons. It hovers over an icon that looks like two overlapping rectangles, typically used for managing window layouts or perspectives.\n",
    "    - 0:11 - 0:12: The mouse clicks on the perspective management icon. A dropdown menu appears with options including \"Show View...\", \"Save Perspective As...\", \"Reset Perspective...\", \"Home\", \"Method Editor\", \"Maintenance\", and \"Monitoring\".\n",
    "    - 0:12 - 0:14: The mouse cursor moves down the dropdown menu and selects \"Reset Perspective...\".\n",
    "    - 0:14 - 0:15: A confirmation dialog box titled \"Reset Perspective\" pops up, asking: \"Do you want to reset the current 'Home' perspective to its defaults?\". \"Yes\" and \"No\" buttons are presented.\n",
    "    - 0:15 - 0:16: The mouse cursor clicks the \"Yes\" button in the confirmation dialog.\n",
    "    - 0:17 - 0:21: The software interface panels dynamically rearrange. The \"TIMS View\" remains at the top. A \"Spectrum View\" now appears in the middle section, and the \"Chromatogram View\" is repositioned to the bottom of the main display area. This is indicative of the default layout for this software.\n",
    "    - 0:21 - 0:23: The software is shown in its new, reset (default) perspective. The mouse cursor makes a brief circular movement over the \"Source\" and \"Syringe Pump\" control area in the lower part of the screen before the video ends.\\n\n",
    "    3. Describe the used equipment:\n",
    "    - Bruker timsControl Software: The primary focus of the video. The window title \"timsTOFscp - ... - timsControl\" indicates this specific software, used for controlling Bruker TIMS-TOF series mass spectrometers.\n",
    "    - Computer System: The software is running on a computer, evidenced by the VNC Viewer window frame and the Windows taskbar visible at the very bottom of the screen.\n",
    "    - (Implied) Bruker timsTOF Mass Spectrometer: The software is designed to control a Trapped Ion Mobility Spectrometry Time-Of-Flight mass spectrometer (e.g., timsTOF Pro, timsTOF SCP, timsTOF fleX). The \"TIMS View\" and other parameters are specific to such instrumentation.\n",
    "    \"\"\"\n",
    "        ]\n",
    "    )\n",
    "    inputs.extend([\"Example Protocol:\"])\n",
    "    inputs.extend(protocol_example_2)\n",
    "    inputs.extend(\n",
    "        [\n",
    "            \"\"\"\n",
    "        # ====== Beginn of Analysis Task ======\\n\n",
    "        ## Important: The analysis must be performed on the following video \\n\n",
    "        Video:\n",
    "        \"\"\"\n",
    "        ]\n",
    "    )\n",
    "    inputs.extend(video)\n",
    "    inputs.extend(\n",
    "        [\n",
    "            \"\"\"\n",
    "        Protocol:\n",
    "    \"\"\"\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    protocol_ai, usage_metadata = video_to_protocol.generate_content_from_model(\n",
    "        inputs,\n",
    "        model_name,\n",
    "        temperature,\n",
    "    )\n",
    "\n",
    "    return protocol_ai, usage_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = \"/Users/patriciaskowronek/Documents/proteomics_specialist/data/benchmark_dataset.csv\"\n",
    "protocol_videos_base = \"/Users/patriciaskowronek/Documents/documentation_agent_few_shot_examples/benchmark_dataset/protocols\"\n",
    "markdown_base = \"/Users/patriciaskowronek/Documents/proteomics_specialist/data\"\n",
    "prefix = \"generate_protocol_video\"\n",
    "\n",
    "all_model_inputs = process_benchmark_dataset(\n",
    "    csv_path, protocol_videos_base, markdown_base, bucket, prefix\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"fewShotExamples\"\n",
    "\n",
    "video_path_example_1 = \"/Users/patriciaskowronek/Documents/documentation_agent_few_shot_examples/ready_examples/Refilling_tuneMix_at_timsTOFUltra.mp4\"\n",
    "protocol_path_example_1 = \"/Users/patriciaskowronek/Documents/documentation_agent_few_shot_examples/ready_examples/Refilling_tuneMix_at_timsTOFUltra.md\"\n",
    "video_path_example_2 = \"/Users/patriciaskowronek/Documents/documentation_agent_few_shot_examples/ready_examples/reset_timsControl.mov\"\n",
    "protocol_path_example_2 = \"/Users/patriciaskowronek/Documents/documentation_agent_few_shot_examples/ready_examples/reset_timsControl.md\"\n",
    "\n",
    "dict_example_1 = prepare_all_inputs(\n",
    "    video_path_example_1,\n",
    "    protocol_path_example_1,\n",
    "    bucket,\n",
    "    prefix,\n",
    ")\n",
    "\n",
    "dict_example_2 = prepare_all_inputs(\n",
    "    video_path_example_2,\n",
    "    protocol_path_example_2,\n",
    "    bucket,\n",
    "    prefix,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"/Users/patriciaskowronek/Documents/documentation_agent_few_shot_examples/knowledge_base\"\n",
    "subfolder_in_bucket = \"knowledge\"\n",
    "unspecific_knowledge = prepare_knowledge(folder_path, bucket, subfolder_in_bucket)\n",
    "\n",
    "folder_path = \"/Users/patriciaskowronek/Documents/documentation_agent_few_shot_examples/knowledge_base_selected\"\n",
    "specific_knowledge = prepare_knowledge(folder_path, bucket, subfolder_in_bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_json_dump(data: dict[str, Any], filename: str | Path) -> None:\n",
    "    \"\"\"Handles non-serializable objects and converts items to strings.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : dict[str, Any]\n",
    "        Dictionary containing the data to be serialized\n",
    "    filename : str | Path\n",
    "        Path to the output JSON file\n",
    "\n",
    "    \"\"\"\n",
    "    path = Path(filename)\n",
    "    temp_file = path.with_suffix(f\"{path.suffix}.tmp\")\n",
    "    with temp_file.open(\"w\") as f:\n",
    "        json.dump(serialize(data), f)\n",
    "    temp_file.replace(path)\n",
    "\n",
    "\n",
    "def serialize(obj: object) -> dict | list | str | int | float | bool | None:\n",
    "    \"\"\"Recursively serialize objects to JSON-compatible types.\"\"\"\n",
    "    if isinstance(obj, dict):\n",
    "        return {k: serialize(v) for k, v in obj.items()}\n",
    "    if isinstance(obj, (list, tuple)):\n",
    "        return [serialize(item) for item in obj]\n",
    "    if isinstance(obj, (int, float, str, bool)) or obj is None:\n",
    "        return obj\n",
    "    return str(obj)\n",
    "\n",
    "\n",
    "def raise_evaluation_error() -> NoReturn:\n",
    "    \"\"\"Raise an error when evaluation contains separator line.\"\"\"\n",
    "    raise ValueError(\"Evaluation contains separator line\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gemini-2.5-pro-preview-03-25\"\n",
    "temperature = 0.9\n",
    "\n",
    "function_configs = [\n",
    "    {\n",
    "        \"name\": \"without_added_knowledge\",\n",
    "        \"function\": protocol_generation_without_added_knowledge,\n",
    "        \"knowledge\": unspecific_knowledge,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"with_examples\",\n",
    "        \"function\": protocol_generation_with_examples,\n",
    "        \"knowledge\": unspecific_knowledge,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"with_thinking_step_by_step\",\n",
    "        \"function\": protocol_generation_with_thinking_step_by_step,\n",
    "        \"knowledge\": unspecific_knowledge,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"with_thinking_step_by_step_plus_unspecific_knowledge\",\n",
    "        \"function\": protocol_generation_with_thinking_step_by_step_plus_knowledge,\n",
    "        \"knowledge\": unspecific_knowledge,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"with_thinking_step_by_step_plus_specific_knowledge\",\n",
    "        \"function\": protocol_generation_with_thinking_step_by_step_plus_knowledge,\n",
    "        \"knowledge\": specific_knowledge,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"with_thinking_step_by_step_plus_specific_knowledge_without_persona\",\n",
    "        \"function\": protocol_generation_with_thinking_step_by_step_plus_knowledge_without_persona,\n",
    "        \"knowledge\": specific_knowledge,\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "# Constants for retry logic\n",
    "WAIT_TIME_BETWEEN_ITEMS = 10  # seconds\n",
    "RETRY_WAIT_TIME = 120  # seconds\n",
    "MAX_RETRIES = 3\n",
    "\n",
    "\n",
    "CHECKPOINT_FILE = \"/Users/patriciaskowronek/Documents/documentation_agent_few_shot_examples/results_protocol_generation/protocol_results_checkpoint.json\"\n",
    "\n",
    "# Load checkpoint\n",
    "results_collection = {}\n",
    "last_processed_key = None\n",
    "last_processed_config = None\n",
    "\n",
    "try:\n",
    "    checkpoint_path = Path(CHECKPOINT_FILE)\n",
    "    if checkpoint_path.exists():\n",
    "        with checkpoint_path.open() as f:\n",
    "            data = json.load(f)\n",
    "            results_collection = data.get(\"results\", {})\n",
    "            last_processed_key = data.get(\"last_key\", None)\n",
    "            last_processed_config = data.get(\"last_config\", None)\n",
    "        print(\n",
    "            f\"Loaded checkpoint. Last processed key: {last_processed_key}, config: {last_processed_config}\"\n",
    "        )\n",
    "except (json.JSONDecodeError, PermissionError, FileNotFoundError) as e:\n",
    "    print(f\"Error loading checkpoint: {e}\")\n",
    "\n",
    "items_list = list(all_model_inputs.items())\n",
    "\n",
    "# Determine starting point\n",
    "start_index = 0\n",
    "start_config_index = 0\n",
    "\n",
    "if last_processed_key:\n",
    "    start_index = next(\n",
    "        (i for i, (k, _) in enumerate(items_list) if k == last_processed_key), 0\n",
    "    )\n",
    "    if last_processed_config:\n",
    "        start_config_index = (\n",
    "            next(\n",
    "                (\n",
    "                    i\n",
    "                    for i, config in enumerate(function_configs)\n",
    "                    if config[\"name\"] == last_processed_config\n",
    "                ),\n",
    "                0,\n",
    "            )\n",
    "            + 1\n",
    "        )\n",
    "        if start_config_index >= len(function_configs):\n",
    "            start_index += 1\n",
    "            start_config_index = 0\n",
    "\n",
    "for i in range(start_index, len(items_list)):\n",
    "    key, value = items_list[i]\n",
    "    print(f\"\\nProcessing item: {key}\")\n",
    "\n",
    "    # Determine config starting point for this item\n",
    "    config_start = start_config_index if i == start_index else 0\n",
    "\n",
    "    for config_idx in range(config_start, len(function_configs)):\n",
    "        config = function_configs[config_idx]\n",
    "\n",
    "        for attempt in range(MAX_RETRIES):\n",
    "            try:\n",
    "                print(f\"\\n--- {config['name']} (attempt {attempt + 1}) ---\")\n",
    "\n",
    "                start_time = time.time()\n",
    "                (\n",
    "                    evaluation,\n",
    "                    ratings_dict,\n",
    "                    usage_metadata_protocol,\n",
    "                    usage_metadata_eval,\n",
    "                ) = generate_protocol_and_evaluate(\n",
    "                    value[\"protocol_video_input\"],\n",
    "                    value[\"protocol_input\"],\n",
    "                    dict_example_1[\"protocol_video_input\"],\n",
    "                    dict_example_1[\"protocol_input\"],\n",
    "                    dict_example_2[\"protocol_video_input\"],\n",
    "                    dict_example_2[\"protocol_input\"],\n",
    "                    config[\"knowledge\"],\n",
    "                    model_name,\n",
    "                    temperature,\n",
    "                    selected_function=config[\"function\"],\n",
    "                )\n",
    "                end_time = time.time()\n",
    "                processing_time = end_time - start_time\n",
    "\n",
    "                print(f\"Processing time: {processing_time:.2f} seconds\")\n",
    "                display(Markdown(evaluation))\n",
    "                display(ratings_dict)\n",
    "\n",
    "                if \"-\" * 500 in evaluation:\n",
    "                    raise_evaluation_error()\n",
    "\n",
    "                # Store results\n",
    "                if key not in results_collection:\n",
    "                    results_collection[key] = {}\n",
    "\n",
    "                results_collection[key][config[\"name\"]] = {\n",
    "                    \"inputs\": {\n",
    "                        \"experiment_name\": key,\n",
    "                        \"config_name\": config[\"name\"],\n",
    "                        \"model_name\": model_name,\n",
    "                        \"temperature\": temperature,\n",
    "                    },\n",
    "                    \"outputs\": {\n",
    "                        \"evaluation\": evaluation,\n",
    "                        \"ratings_dict\": ratings_dict,\n",
    "                        \"usage_metadata_protocol\": usage_metadata_protocol,\n",
    "                        \"usage_metadata_eval\": usage_metadata_eval,\n",
    "                        \"processing_time\": processing_time,\n",
    "                    },\n",
    "                }\n",
    "\n",
    "                # Save checkpoint after each successful config\n",
    "                safe_json_dump(\n",
    "                    {\n",
    "                        \"last_key\": key,\n",
    "                        \"last_config\": config[\"name\"],\n",
    "                        \"results\": results_collection,\n",
    "                    },\n",
    "                    CHECKPOINT_FILE,\n",
    "                )\n",
    "\n",
    "                print(\n",
    "                    f\"Waiting {WAIT_TIME_BETWEEN_ITEMS} seconds before next config...\"\n",
    "                )\n",
    "                time.sleep(WAIT_TIME_BETWEEN_ITEMS)\n",
    "                break  # Success, exit retry loop\n",
    "\n",
    "            except Exception:\n",
    "                logging.exception(\n",
    "                    f\"Unexpected error processing {key} with {config['name']}\"\n",
    "                )\n",
    "                if attempt < MAX_RETRIES - 1:\n",
    "                    logging.info(f\"Waiting {RETRY_WAIT_TIME} seconds before retry...\")\n",
    "                    time.sleep(RETRY_WAIT_TIME)\n",
    "                else:\n",
    "                    logging.exception(\n",
    "                        f\"Max retries reached for {key} with {config['name']}, moving to next config\"\n",
    "                    )\n",
    "                    # Save checkpoint even on failure\n",
    "                    safe_json_dump(\n",
    "                        {\n",
    "                            \"last_key\": key,\n",
    "                            \"last_config\": config[\"name\"],\n",
    "                            \"results\": results_collection,\n",
    "                        },\n",
    "                        CHECKPOINT_FILE,\n",
    "                    )\n",
    "\n",
    "# Save final results\n",
    "try:\n",
    "    timestamp = time.time()\n",
    "    results_path = Path(CHECKPOINT_FILE).parent\n",
    "    final_results_file = results_path / f\"final_protocol_results_{timestamp}.json\"\n",
    "    safe_json_dump(results_collection, final_results_file)\n",
    "    print(\"All processing complete. Final results saved.\")\n",
    "except (PermissionError, OSError) as e:\n",
    "    print(f\"Error saving final results: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logic to repeat analysis of single videos\n",
    "\n",
    "CHECKPOINT_FILE = \"/Users/patriciaskowronek/Documents/documentation_agent_few_shot_examples/results_protocol_generation/protocol_results_checkpoint9.json\"\n",
    "\n",
    "# Define specific items to process with their configurations\n",
    "ITEMS_TO_PROCESS = {\n",
    "    \"UltraSourceToESIsource_protocolCorrect\": [\n",
    "        \"with_thinking_step_by_step_plus_unspecific_knowledge\"\n",
    "    ],\n",
    "    \"DisconnectColumn_protocolCorrect\": [\"without_added_knowledge\"],\n",
    "    \"Evotip_protocolCorrect\": [\"with_thinking_step_by_step\"],\n",
    "    \"TimsCalibration_protocolCorrect\": [\"with_examples\"],\n",
    "    \"TimsCalibration_protocolCorrect\": [\n",
    "        \"with_thinking_step_by_step_plus_specific_knowledge_without_persona\"\n",
    "    ],\n",
    "    \"QueueSamples_protocolCorrect\": [\n",
    "        \"with_thinking_step_by_step_plus_specific_knowledge\"\n",
    "    ],\n",
    "    \"QueueSamples_protocolCorrect\": [\n",
    "        \"with_thinking_step_by_step_plus_specific_knowledge_without_persona\"\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Load checkpoint\n",
    "results_collection = {}\n",
    "last_processed_key = None\n",
    "last_processed_config = None\n",
    "\n",
    "try:\n",
    "    checkpoint_path = Path(CHECKPOINT_FILE)\n",
    "    if checkpoint_path.exists():\n",
    "        with checkpoint_path.open() as f:\n",
    "            data = json.load(f)\n",
    "            results_collection = data.get(\"results\", {})\n",
    "            last_processed_key = data.get(\"last_key\", None)\n",
    "            last_processed_config = data.get(\"last_config\", None)\n",
    "        print(\n",
    "            f\"Loaded checkpoint. Last processed key: {last_processed_key}, config: {last_processed_config}\"\n",
    "        )\n",
    "except (json.JSONDecodeError, PermissionError, FileNotFoundError) as e:\n",
    "    print(f\"Error loading checkpoint: {e}\")\n",
    "\n",
    "# Create a list of (key, config_name) tuples to process\n",
    "items_to_process_list = []\n",
    "for key, config_names in ITEMS_TO_PROCESS.items():\n",
    "    items_to_process_list.extend((key, config_name) for config_name in config_names)\n",
    "\n",
    "# Determine starting point based on checkpoint\n",
    "start_index = 0\n",
    "if last_processed_key and last_processed_config:\n",
    "    checkpoint_tuple = (last_processed_key, last_processed_config)\n",
    "    try:\n",
    "        start_index = items_to_process_list.index(checkpoint_tuple) + 1\n",
    "    except ValueError:\n",
    "        # If checkpoint not found in our list, start from beginning\n",
    "        start_index = 0\n",
    "\n",
    "print(f\"Starting processing from index {start_index}\")\n",
    "print(f\"Total items to process: {len(items_to_process_list)}\")\n",
    "\n",
    "for i in range(start_index, len(items_to_process_list)):\n",
    "    key, config_name = items_to_process_list[i]\n",
    "\n",
    "    # Check if key exists in all_model_inputs\n",
    "    if key not in all_model_inputs:\n",
    "        print(f\"Warning: Key '{key}' not found in all_model_inputs, skipping...\")\n",
    "        continue\n",
    "\n",
    "    # Find the config in function_configs\n",
    "    config = None\n",
    "    for cfg in function_configs:\n",
    "        if cfg[\"name\"] == config_name:\n",
    "            config = cfg\n",
    "            break\n",
    "\n",
    "    if config is None:\n",
    "        print(\n",
    "            f\"Warning: Config '{config_name}' not found in function_configs, skipping...\"\n",
    "        )\n",
    "        continue\n",
    "\n",
    "    value = all_model_inputs[key]\n",
    "    print(\n",
    "        f\"\\nProcessing item: {key} with config: {config_name} ({i + 1}/{len(items_to_process_list)})\"\n",
    "    )\n",
    "\n",
    "    for attempt in range(MAX_RETRIES):\n",
    "        try:\n",
    "            print(f\"\\n--- {config['name']} (attempt {attempt + 1}) ---\")\n",
    "\n",
    "            start_time = time.time()\n",
    "            evaluation, ratings_dict, usage_metadata_protocol, usage_metadata_eval = (\n",
    "                generate_protocol_and_evaluate(\n",
    "                    value[\"protocol_video_input\"],\n",
    "                    value[\"protocol_input\"],\n",
    "                    dict_example_1[\"protocol_video_input\"],\n",
    "                    dict_example_1[\"protocol_input\"],\n",
    "                    dict_example_2[\"protocol_video_input\"],\n",
    "                    dict_example_2[\"protocol_input\"],\n",
    "                    config[\"knowledge\"],\n",
    "                    model_name,\n",
    "                    temperature,\n",
    "                    selected_function=config[\"function\"],\n",
    "                )\n",
    "            )\n",
    "            end_time = time.time()\n",
    "            processing_time = end_time - start_time\n",
    "\n",
    "            print(f\"Processing time: {processing_time:.2f} seconds\")\n",
    "            display(Markdown(evaluation))\n",
    "            display(ratings_dict)\n",
    "\n",
    "            if \"-\" * 500 in evaluation:\n",
    "                raise_evaluation_error()\n",
    "\n",
    "            # Store results\n",
    "            if key not in results_collection:\n",
    "                results_collection[key] = {}\n",
    "\n",
    "            results_collection[key][config[\"name\"]] = {\n",
    "                \"inputs\": {\n",
    "                    \"experiment_name\": key,\n",
    "                    \"config_name\": config[\"name\"],\n",
    "                    \"model_name\": model_name,\n",
    "                    \"temperature\": temperature,\n",
    "                },\n",
    "                \"outputs\": {\n",
    "                    \"evaluation\": evaluation,\n",
    "                    \"ratings_dict\": ratings_dict,\n",
    "                    \"usage_metadata_protocol\": usage_metadata_protocol,\n",
    "                    \"usage_metadata_eval\": usage_metadata_eval,\n",
    "                    \"processing_time\": processing_time,\n",
    "                },\n",
    "            }\n",
    "\n",
    "            # Save checkpoint after each successful config\n",
    "            safe_json_dump(\n",
    "                {\n",
    "                    \"last_key\": key,\n",
    "                    \"last_config\": config[\"name\"],\n",
    "                    \"results\": results_collection,\n",
    "                },\n",
    "                CHECKPOINT_FILE,\n",
    "            )\n",
    "\n",
    "            print(f\"Successfully processed {key} with {config_name}\")\n",
    "\n",
    "            # Only wait if there are more items to process\n",
    "            if i < len(items_to_process_list) - 1:\n",
    "                print(f\"Waiting {WAIT_TIME_BETWEEN_ITEMS} seconds before next item...\")\n",
    "                time.sleep(WAIT_TIME_BETWEEN_ITEMS)\n",
    "\n",
    "            break  # Success, exit retry loop\n",
    "\n",
    "        except Exception:\n",
    "            logging.exception(\n",
    "                f\"Unexpected error processing {key} with {config['name']}\"\n",
    "            )\n",
    "            if attempt < MAX_RETRIES - 1:\n",
    "                logging.info(f\"Waiting {RETRY_WAIT_TIME} seconds before retry...\")\n",
    "                time.sleep(RETRY_WAIT_TIME)\n",
    "            else:\n",
    "                logging.exception(\n",
    "                    f\"Max retries reached for {key} with {config['name']}, moving to next item\"\n",
    "                )\n",
    "                # Save checkpoint even on failure\n",
    "                safe_json_dump(\n",
    "                    {\n",
    "                        \"last_key\": key,\n",
    "                        \"last_config\": config[\"name\"],\n",
    "                        \"results\": results_collection,\n",
    "                    },\n",
    "                    CHECKPOINT_FILE,\n",
    "                )\n",
    "\n",
    "# Save final results\n",
    "try:\n",
    "    timestamp = time.time()\n",
    "    results_path = Path(CHECKPOINT_FILE).parent\n",
    "    final_results_file = results_path / f\"final_protocol_results_{timestamp}.json\"\n",
    "    safe_json_dump(results_collection, final_results_file)\n",
    "    print(\"All processing complete. Final results saved.\")\n",
    "    print(\n",
    "        f\"Processed {len([k for k in results_collection if k in ITEMS_TO_PROCESS])} items total\"\n",
    "    )\n",
    "except (PermissionError, OSError) as e:\n",
    "    print(f\"Error saving final results: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = \"\"\"\n",
    "Step 2: AI-Generated Protocol (Verbatim)\\n\\n# Connecting an IonOpticks Column to a Bruker timsTOF SCP Mass Spectrometer and Initiating LC-MS Operation\\n\\n## Abstract\\nThis protocol details the procedure for connecting an IonOpticks analytical column, via its sample line, to the UltraSource of a Bruker timsTOF SCP mass spectrometer. It includes steps for verifying system readiness in timsControl and HyStar software, making the fluidic connection, ensuring proper column heating and grounding, and initiating system operation to observe a signal. This procedure is essential for preparing the LC-MS system for data acquisition.\\n\\n## Materials\\n\\n### Equipment\\n- **Bruker timsTOF SCP Mass Spectrometer:** Equipped with an UltraSource and integrated column oven.\\n- **Evosep One LC System:** (or compatible nanoLC system)\\n- **IonOpticks Column:** Pre-installed in the column oven assembly (e.g., Aurora Series).\\n- **Sample Line:** Fused silica capillary with appropriate nano-fitting (e.g., PEEK fitting) for connection to the IonOpticks column inlet.\\n- **Metal Adapter (optional, for tightening):** To aid in gripping the sample line fitting if necessary (removed after connection).\\n- **Flat-Jawed Pliers:** For counter-holding the column inlet fitting during connection (e.g., Knipex Pliers Wrench).\\n- **Computer Workstation:** Running Bruker timsControl and Bruker HyStar software.\\n- **Personal Protective Equipment:** Nitrile gloves.\\n\\n### Reagents\\n- Solvents for LC system (appropriate for column flushing and operation, e.g., mobile phases A and B).\\n\\n## Procedure\\n*Estimated timing: Approximately 3 minutes*\\n\\n### 1. Verify Mass Spectrometer Status in timsControl\\n1.  Navigate to the Bruker timsControl software.\\n2.  Check the \"Automation\" status panel. If the system is in \"Operating\" mode, click on the \"HyStar\" button (or equivalent control for your LC) to switch the mass spectrometer to \"Standby by\" mode.\\n*   **CRITICAL STEP** For IonOpticks columns, ensure the MS is not in \"Operate\" mode for extended periods without flow, and conversely, ensure it is in \"Standby\" if flow is active but no acquisition is running, to prevent damage.\\n\\n### 2. Prepare and Connect the Sample Line to the IonOpticks Column\\n1.  Confirm that the IonOpticks column is already installed in the column oven, and the oven is mounted on the UltraSource.\\n2.  Take the sample line originating from the LC system.\\n3.  If using a metal adapter for easier tightening, push it onto the PEEK fitting of the sample line.\\n4.  Inspect the open end of the sample line capillary. Ensure it is clean and patent. If necessary, carefully trim the end.\\n5.  Carefully hold the inlet fitting of the installed IonOpticks column using flat-jawed pliers to provide counter-torque.\\n6.  Insert the sample line fitting (with or without the metal adapter) into the column's inlet fitting.\\n7.  Hand-tighten the sample line fitting into the column connector until finger-tight. **CAUTION:** Do not overtighten, as this can damage the fittings or the column.\\n8.  If a metal adapter was used on the sample line fitting, remove it now.\\n\\n### 3. Verify Column Oven and Grounding\\n1.  Ensure the column oven assembly is positioned correctly, typically as close as possible to the ion source inlet. Adjust using the positioning screw if necessary.\\n2.  Verify that a grounding screw is making contact with the column assembly or its connector to ensure proper grounding. Multiple grounding points may be available; ensure at least one is correctly engaged.\\n3.  Close the column oven lid. A click should be audible.\\n4.  Observe the LED indicator lights on the column oven. Three blinking green lights indicate the oven is heating to its setpoint (e.g., 50 Â°C). The lights will become solid once the temperature is reached.\\n\\n### 4. Initiate System Operation and Verify Signal\\n1.  Return to the Bruker timsControl software.\\n2.  Click on the \"HyStar\" button (or equivalent LC control) in the \"Automation\" panel to switch the mass spectrometer to \"Operating\" mode.\\n3.  Navigate to the Bruker HyStar software (or your LC control software).\\n4.  Verify that \"Idle Flow\" is active. If not, initiate idle flow (e.g., by right-clicking and selecting an \"Idle Flow run\" or similar command).\\n5.  Once the LC system indicates flow and the MS is in operate mode, observe the timsControl software for a stable spray and detection of ions (e.g., background ions from the mobile phase).\\n\\n## Expected Results\\n- The sample line is securely connected to the IonOpticks column without leaks.\\n- The column oven is closed and heating to the set temperature (e.g., 50 Â°C), indicated by the LEDs.\\n- The column is properly grounded.\\n- The timsTOF SCP mass spectrometer is in \"Operating\" mode.\\n- The LC system is delivering flow (idle flow).\\n- A stable ion signal is observable in the timsControl software, indicating the system is ready for sample analysis.\\n\\n## Figures\\n### Figure 1: Software Status Check in timsControl.\\n[Placeholder for a screenshot showing the timsControl interface with the \"Automation\" panel, highlighting the switch from \"Operating\" to \"Standby by\" (0:16-0:24).]\\n\\n### Figure 2: Connecting the Sample Line to the IonOpticks Column.\\n[Placeholder for an image depicting the hand-tightening of the sample line fitting into the column inlet fitting, with pliers used for counter-holding (1:06-1:16).]\\n\\n### Figure 3: Column Oven and Grounding Verification.\\n[Placeholder for an image showing the closed column oven with blinking/solid green LED temperature indicators and a finger pointing to a grounding screw (2:00-2:10).]\\n\\n### Figure 4: System Operating with Signal in timsControl.\\n[Placeholder for a screenshot of the timsControl interface in \"Operating\" mode, displaying chromatogram and mass spectrum views indicating a live signal (2:38-2:41).]\\n\\n## References\\n1.  Bruker timsTOF Series User Manuals.\\n2.  Evosep One User Manual (or relevant LC system manual).\\n3.  IonOpticks Column Handling and Installation Guide.\\n\\n###\"\"\"\n",
    "\n",
    "display(Markdown(content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "docu_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
