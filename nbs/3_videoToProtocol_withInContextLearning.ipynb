{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Documention Agent\n",
    "\n",
    "This notebook demonstrates a documention agent:\n",
    "1. Video-to-protocol conversion using Vertex AI\n",
    "2. With knowledge from documents and pictures that are loaded into cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install google-cloud-storage\n",
    "# %pip install --upgrade --user --quiet google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../secrets.ini']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %load_ext autoreload\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import configparser\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "from IPython.display import Markdown\n",
    "\n",
    "path_to_append = Path(Path.cwd()).parent / \"proteomics_specialist\"\n",
    "sys.path.append(str(path_to_append))\n",
    "import video_to_protocol\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read(\"../secrets.ini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "\n",
    "import vertexai\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read(\"../secrets.ini\")\n",
    "\n",
    "PROJECT_ID = config[\"DEFAULT\"][\"PROJECT_ID\"]\n",
    "vertexai.init(project=PROJECT_ID, location=\"europe-west9\")  # europe-west9 is Paris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "\n",
    "os.environ[\"GOOGLE_CLOUD_PROJECT\"] = config[\"DEFAULT\"][\"PROJECT_ID\"]\n",
    "\n",
    "# Initialize Cloud Storage client\n",
    "storage_client = storage.Client()\n",
    "bucket_name = \"mannlab_videos\"\n",
    "bucket = storage_client.bucket(bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "from vertexai.generative_models import Part\n",
    "from vertexai.preview import caching\n",
    "from vertexai.preview.generative_models import GenerativeModel\n",
    "\n",
    "MODEL_ID = \"gemini-1.5-pro-001\"\n",
    "\n",
    "# Following: https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/context-caching/intro_context_caching_vertex_ai_sdk.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload knowledge files to Google Cloud Storage\n",
    "folder_path = \"/Users/patriciaskowronek/Documents/documentation_agent_few_shot_examples/knowledge_base\"\n",
    "subfolder_in_bucket = \"knowledge\"\n",
    "\n",
    "knowledge_uris = []\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.lower().endswith(\n",
    "        (\".jpg\", \".jpeg\", \".gif\", \".bmp\", \".tiff\", \".tif\", \".pdf\")\n",
    "    ):\n",
    "        path = Path(folder_path) / filename\n",
    "        try:\n",
    "            file_uri = video_to_protocol.upload_video_to_gcs(\n",
    "                path, bucket, subfolder_in_bucket\n",
    "            )\n",
    "            knowledge_uris.append(file_uri)\n",
    "        except OSError as e:\n",
    "            print(f\"Error processing {filename}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files processed: 40\n",
      "  PDF: 40\n",
      "Cached content created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Create cache with Vertex AI\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "# Define supported file types with corresponding MIME types\n",
    "MIME_TYPES = {\n",
    "    \".pdf\": \"application/pdf\",\n",
    "    \".jpg\": \"image/jpeg\",\n",
    "    \".jpeg\": \"image/jpeg\",\n",
    "    \".png\": \"image/png\",\n",
    "}\n",
    "\n",
    "\n",
    "def create_cached_content(\n",
    "    knowledge_uris: list[str],\n",
    "    model_id: str,\n",
    ") -> list[Part]:\n",
    "    \"\"\"Create cached content from knowledge URIs.\n",
    "\n",
    "    Args:\n",
    "        knowledge_uris: list of URIs pointing to knowledge files\n",
    "        bucket_name: Name of the GCS bucket\n",
    "        subfolder_in_bucket: Subfolder path in the bucket\n",
    "        model_id: ID of the model to use\n",
    "\n",
    "    Returns:\n",
    "        list of Part objects created from the knowledge URIs\n",
    "\n",
    "    \"\"\"\n",
    "    contents = []\n",
    "    file_counts = defaultdict(int)\n",
    "\n",
    "    for file_path in knowledge_uris:\n",
    "        path_obj = Path(file_path)\n",
    "        file_ext = path_obj.suffix.lower()\n",
    "\n",
    "        if file_ext in MIME_TYPES:\n",
    "            mime_type = MIME_TYPES[file_ext]\n",
    "\n",
    "            try:\n",
    "                contents.append(Part.from_uri(file_path, mime_type=mime_type))\n",
    "                file_counts[file_ext] += 1\n",
    "            except (OSError, ValueError) as e:\n",
    "                print(f\"Error creating Part from {file_path}: {e}\")\n",
    "        else:\n",
    "            print(f\"Unsupported file extension: {file_ext}\")\n",
    "\n",
    "    print(f\"Total files processed: {len(contents)}\")\n",
    "    for ext, count in file_counts.items():\n",
    "        print(f\"  {ext[1:].upper()}: {count}\")\n",
    "\n",
    "    if contents:\n",
    "        cached_content = caching.CachedContent.create(\n",
    "            model_name=model_id,\n",
    "            contents=contents,\n",
    "            ttl=datetime.timedelta(minutes=60),\n",
    "        )\n",
    "        print(\"Cached content created successfully!\")\n",
    "        return cached_content\n",
    "    print(\"No matching files found. Cached content not created.\")\n",
    "    return None\n",
    "\n",
    "\n",
    "cached_content = create_cached_content(knowledge_uris, model_id=MODEL_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cached_content.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4513486435927457792\n",
      "2025-03-24 12:08:53.496338+00:00\n",
      "2025-03-24 13:08:53.490116+00:00\n"
     ]
    }
   ],
   "source": [
    "print(cached_content.name)\n",
    "# print(cached_content.resource_name)\n",
    "# print(cached_content.model_name)\n",
    "print(cached_content.create_time)\n",
    "print(cached_content.expire_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GenerativeModel.from_cached_content(cached_content=cached_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = \"/Users/patriciaskowronek/Documents/documentation_agent_few_shot_examples/ready_examples/Disconnect_IonOpticks_column_from_sample_line.mp4\"\n",
    "video_uri_input = video_to_protocol.upload_video_to_gcs(video_path, bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "You are a highly observant research assistant in Professor Matthias Mann's proteomics and mass spectrometry laboratory. Your expertise lies in detailed documentation of experimental procedures.\n",
    "\n",
    "Analyze the video and reconstruct a step-by-step protocol by focusing on the actions in the video. Focus on user interactions with equipment, devices, and software. The goal is a clear, concise, unambiguous protocol reproducible by someone with no prior knowledge. \"Think aloud\" as if you were the researcher in the video that describes their work. Describe what you see at every secound. Take deep breath and think step-by-step. Answer direct.\n",
    "\n",
    "For each action, describe:\n",
    "\n",
    "* **Timestamp:** [timestamp]\n",
    "* **Action:** [Specific Action/Change Observed (Include details of tools used, and observable results. (e.g., opening a lid, pressing a button, turning a knob, screwing/unscrewing, connecting/disconnecting, etc.))]\n",
    "\n",
    "**Example:**\n",
    "[02:15] timsControl Software: Mode changed from \"Operate\" to \"Standby\" by clicking the power button.\n",
    "[03:45] Ion Source: NanoViper connector disconnected by unscrewing the nut counterclockwise.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 275833\n",
      "candidates_token_count: 242\n",
      "total_token_count: 276075\n",
      "cached_content_token_count: 261613\n",
      "prompt_tokens_details {\n",
      "  modality: TEXT\n",
      "  token_count: 256\n",
      "}\n",
      "prompt_tokens_details {\n",
      "  modality: VIDEO\n",
      "  token_count: 13965\n",
      "}\n",
      "prompt_tokens_details {\n",
      "  modality: DOCUMENT\n",
      "  token_count: 261612\n",
      "}\n",
      "candidates_tokens_details {\n",
      "  modality: TEXT\n",
      "  token_count: 242\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The video shows a researcher connecting a separation column to a mass spectrometer. Here is a step-by-step protocol of the actions:\n",
       "\n",
       "* **[0:14]** **Action:** The researcher reaches for the separation column and the emitter, which are already connected via a union.\n",
       "* **[0:15]** **Action:** The researcher holds the separation column with their left hand and the emitter with their right hand.\n",
       "* **[0:19]** **Action:** The researcher carefully inserts the emitter into the source.\n",
       "* **[0:21]** **Action:** The researcher uses their right hand to tighten the propeller-shaped metal ring that secures the emitter to the source.\n",
       "* **[0:33]** **Action:** The researcher uses pliers to tighten the propeller-shaped metal ring further.\n",
       "* **[0:40]** **Action:** The researcher places the pliers in a yellow container.\n",
       "* **[0:41]** **Action:** The researcher reaches for the transfer line.\n",
       "* **[0:42]** **Action:** The researcher connects the transfer line to the separation column using a NanoViper connector. \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = [\n",
    "    prompt,\n",
    "    \"Input Video:\",\n",
    "    Part.from_uri(video_uri_input, mime_type=\"video/mp4\"),\n",
    "    \"Observations:\",\n",
    "]\n",
    "\n",
    "response = model.generate_content(inputs, generation_config={\"temperature\": 0})\n",
    "observation = response.text\n",
    "print(response.usage_metadata)\n",
    "Markdown(observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "docu_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
